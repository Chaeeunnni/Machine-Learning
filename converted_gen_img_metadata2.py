from openai import OpenAI
import base64
import json
import os
from tqdm import tqdm
import time
from dotenv import load_dotenv
load_dotenv()
# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(
    api_key = os.getenv("OPENAI_API_KEY")
)

def describe_image_with_gpt4v(image_path):
    """GPT-4Vë¥¼ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
    try:
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì§¤ ì´ë¯¸ì§€ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n1. ê°ì • í‘œí˜„: \n2. ìƒí™©/ë§¥ë½: \n3. ìºë¦­í„° í–‰ë™: \n4. ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ëŒ€í™” ìƒí™©: "
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=300
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error processing image {image_path}: {e}")
        return None


def extract_usage_context_from_description(description):
    """GPT-4V ì„¤ëª…ì—ì„œ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ"""
    if not description:
        return []

    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ
    context_keywords = {
        "ì¶•í•˜": ["ì¶•í•˜", "ì„±ê³µ", "ê¸°ì¨", "ë‹¬ì„±"],
        "ìœ„ë¡œ": ["ìŠ¬í””", "ìœ„ë¡œ", "í˜ë“¦", "ìš°ìš¸"],
        "ê²©ë ¤": ["ì‘ì›", "ê²©ë ¤", "í™”ì´íŒ…", "íŒŒì´íŒ…"],
        "ê³µê°": ["ì´í•´", "ê³µê°", "ë™ê°"],
        "ì¡°ì–¸": ["ì¡°ì–¸", "ì¶©ê³ ", "ë„ì›€"],
        "ìœ ë¨¸": ["ì›ƒê¹€", "ì¬ë¯¸", "ë†ë‹´", "ê°œê·¸"],
        "ë¶„ë…¸": ["í™”ë‚¨", "ì§œì¦", "ë¶„ë…¸"],
        "ë†€ëŒ": ["ë†€ëŒ", "ë‹¹í™©", "ì¶©ê²©"],
        "ì—…ë¬´": ["ì¼", "ì—…ë¬´", "ì§ì¥", "íšŒì‚¬"],
        "ì—°ì• ": ["ì‚¬ë‘", "ì—°ì• ", "ë°ì´íŠ¸", "ì»¤í”Œ"],
        "ì¹œêµ¬": ["ì¹œêµ¬", "ìš°ì •", "ëª¨ì„"],
        "ê°€ì¡±": ["ê°€ì¡±", "ë¶€ëª¨", "í˜•ì œ"]
    }

    contexts = []
    for context, keywords in context_keywords.items():
        if any(keyword in description for keyword in keywords):
            contexts.append(context)

    return contexts


def process_single_image(image_info, base_data_path):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    # image_metadata.jsonì˜ filepath: "ê¸°ì¨/ê°ì‚¬í•˜ëŠ”/img003.jpg"
    # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ: MLproject/data/images/ê¸°ì¨/ê°ì‚¬í•˜ëŠ”/img003.jpg
    full_image_path = os.path.join(base_data_path, "images", image_info['filepath'])

    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€: {image_info['filepath']}")
    print(f"ì „ì²´ ê²½ë¡œ: {full_image_path}")

    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(full_image_path):
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_image_path}")
        return {
            **image_info,
            "text_description": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
            "usage_context": [],
            "processing_status": "file_not_found"
        }

    # GPT-4Vë¡œ ì„¤ëª… ìƒì„±
    print("ğŸ”„ GPT-4Vë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
    description = describe_image_with_gpt4v(full_image_path)

    if description:
        print("âœ… ì„¤ëª… ìƒì„± ì™„ë£Œ")
        # ì„¤ëª…ì—ì„œ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ
        usage_contexts = extract_usage_context_from_description(description)
    else:
        print("âŒ ì„¤ëª… ìƒì„± ì‹¤íŒ¨")
        usage_contexts = []

    # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ì— ì„¤ëª… ì¶”ê°€
    enhanced_metadata = {
        **image_info,
        "text_description": description if description else "ì„¤ëª… ìƒì„± ì‹¤íŒ¨",
        "usage_context": usage_contexts,
        "processing_status": "success" if description else "failed",
        "processed_path": full_image_path  # ë””ë²„ê¹…ìš©
    }

    # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
    time.sleep(1)

    return enhanced_metadata


def verify_image_structure(base_data_path):
    """ì´ë¯¸ì§€ í´ë” êµ¬ì¡° í™•ì¸"""
    images_path = os.path.join(base_data_path, "images")

    if not os.path.exists(images_path):
        print(f"âŒ images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_path}")
        return False

    print(f"âœ… images í´ë” í™•ì¸: {images_path}")

    # ëŒ€ë¶„ë¥˜ í´ë”ë“¤ í™•ì¸
    categories = []
    for item in os.listdir(images_path):
        item_path = os.path.join(images_path, item)
        if os.path.isdir(item_path):
            categories.append(item)
            print(f"  ğŸ“ ëŒ€ë¶„ë¥˜: {item}")

            # ì†Œë¶„ë¥˜ í´ë”ë“¤ í™•ì¸
            for subitem in os.listdir(item_path):
                subitem_path = os.path.join(item_path, subitem)
                if os.path.isdir(subitem_path):
                    # ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ í™•ì¸
                    image_files = [f for f in os.listdir(subitem_path)
                                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))]
                    print(f"    ğŸ“‚ ì†Œë¶„ë¥˜: {subitem} ({len(image_files)}ê°œ ì´ë¯¸ì§€)")

    return True


def batch_process_images():
    """ë°°ì¹˜ë¡œ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬"""
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = "/Users/nahyeon/2025-1/ê¸°ê³„í•™ìŠµê°œë¡ /Machine-Learning"  # ì‹¤ì œ í”„ë¡œì íŠ¸ í´ë”ëª…ì— ë§ê²Œ ìˆ˜ì •

    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    metadata_path = os.path.join(project_root, "data", "image_metadata.json")
    output_path = os.path.join(project_root, "data", "enhanced_image_metadata.json")

    # ë°ì´í„° í´ë” ê²½ë¡œ
    data_path = os.path.join(project_root, "data")

    print("=" * 50)
    print("ğŸš€ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ìë™ ìƒì„± ì‹œì‘")
    print("=" * 50)
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼: {metadata_path}")
    print(f"ì¶œë ¥ íŒŒì¼: {output_path}")
    print()

    # í´ë” êµ¬ì¡° í™•ì¸
    print("ğŸ“ ì´ë¯¸ì§€ í´ë” êµ¬ì¡° í™•ì¸ ì¤‘...")
    if not verify_image_structure(data_path):
        return
    print()

    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(metadata_path):
        print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
        return

    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    with open(metadata_path, 'r', encoding='utf-8') as f:
        image_data = json.load(f)

    print(f"ğŸ“Š ì´ {len(image_data)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    print()

    # ìˆœì°¨ ì²˜ë¦¬ (API ì œí•œì„ ê³ ë ¤)
    enhanced_data = []
    successful_count = 0
    failed_count = 0

    for i, image_info in enumerate(tqdm(image_data, desc="Processing images")):
        print(f"\n[{i + 1}/{len(image_data)}] ", end="")
        result = process_single_image(image_info, data_path)
        enhanced_data.append(result)

        if result.get('processing_status') == 'success':
            successful_count += 1
        else:
            failed_count += 1

        # 10ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        if (i + 1) % 10 == 0:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {i + 1}ê°œ ì²˜ë¦¬ë¨ (ì„±ê³µ: {successful_count}, ì‹¤íŒ¨: {failed_count})")

    # ìµœì¢… ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(enhanced_data, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 50)
    print("ğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {successful_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {output_path}")
    print("=" * 50)


# ì‹¤í–‰
if __name__ == "__main__":
    batch_process_images()