from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
import os


class HybridMatcher:
    def __init__(self, metadata_file="data/enhanced_image_metadata.json"):
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = []
        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                print(f"[*] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.metadata)}ê°œ ì´ë¯¸ì§€")
            except Exception as e:
                print(f"[!] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        # í™•ì¥ëœ ê°ì • í‚¤ì›Œë“œ
        self.emotion_keywords = {
            'í™”ë‚˜ë‹¤': ['í™”', 'ì§œì¦', 'ë¹¡', 'ë¶„ë…¸', 'ì—´ë°›', 'ê¸°ë§‰', 'ë¶„í•˜ë‹¤', 'ì„±ë‚˜ë‹¤',
                    'ë¶„í•´', 'ì•½ì˜¤ë¥´', 'ë¹¡ì¹˜', 'ì—´ë¶ˆë‚˜', 'ì†í„°ì ¸', 'ê³¨ì¹˜',
                    'ê±°ìŠ¬ë ¤', 'ì§œì¦ë‚˜', 'í™”ë‚˜', 'ì—´ë°›ì•„', 'ë¶„í•˜ê³ ', 'ì„­ì„­í•´', 'ì–µìš¸',
                    'ì–´ì´ì—†', 'ë‹µë‹µ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'ë¹¡ì³', 'ì—´ë‚˜', 'ë¹ˆì •', 'ì•½ì˜¬ë¼'],

            'ìŠ¬í”„ë‹¤': ['ìŠ¬í”ˆ', 'ìš°ìš¸', 'ì†ìƒ', 'ì„œëŸ½', 'ëˆˆë¬¼', 'ìš¸ê³ ', 'ì„œê¸€',
                    'ìŠ¬í¼', 'ìš°ìš¸í•´', 'ì„œëŸ¬ì›Œ', 'ëˆˆë¬¼ë‚˜', 'ë§ˆìŒì•„í”ˆ', 'ê°€ìŠ´ì•„í”ˆ',
                    'ì“¸ì“¸', 'ì™¸ë¡œì›Œ', 'í—ˆì „', 'í—¤ì–´ì ¸', 'ì´ë³„', 'ê·¸ë¦¬ì›Œ',
                    'ì‹¤ë§', 'ì‹¤ë§ìŠ¤ëŸ¬', 'ì„œìš´', 'ì•ˆíƒ€ê¹Œ', 'ê°€ìŠ´', 'ë§ˆìŒ', 'ìƒì²˜'],

            'ê¸°ì˜ë‹¤': ['ê¸°ìœ', 'í–‰ë³µ', 'ì¢‹ë‹¤', 'ì‹ ë‚˜', 'ì¦ê±°', 'ë§Œì¡±', 'ê¸°ë»',
                    'ì¢‹ì•„', 'í–‰ë³µí•´', 'ê¸°ë¶„ì¢‹', 'ì‹ ì´ë‚˜', 'ì¦ê±°ì›Œ', 'ë§Œì¡±í•´',
                    'ì„±ê³µ', 'ìŠ¹ì§„', 'í•©ê²©', 'ì¶•í•˜', 'ê¸°ë»ìš”', 'ì¢‹ë„¤', 'ìµœê³ ',
                    'ì„¤ë ˆ', 'ì„¤ë ˜', 'ë“¤ëœ¨', 'ê¸°ëŒ€', 'í™˜ìƒ', 'ì™„ë²½', 'ë©‹ì ¸'],

            'ë¬´ì„­ë‹¤': ['ë¬´ì„œ', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ë‘ë ¤', 'ë¬´ì„œì›Œ', 'ê±±ì •ë˜',
                    'ë¶ˆì•ˆí•´', 'ë‘ë ¤ì›Œ', 'ë¬´ì‹œë¬´ì‹œ', 'ì‹¬ë€', 'ì¡°ë§ˆì¡°ë§ˆ',
                    'ê±±ì •ìŠ¤ëŸ¬', 'ì—¼ë ¤', 'ê·¼ì‹¬', 'ìš°ë ¤', 'ë¬´ì„œìš´'],

            'ë†€ëë‹¤': ['ë†€ë¼', 'ì‹ ê¸°', 'ëŒ€ë°•', 'í—', 'ì™€', 'ë‹¹í™©', 'ì–´ì©Œì§€',
                    'ë†€ë¼ì›Œ', 'ì‹ ê¸°í•´', 'ë‹¹í™©ìŠ¤ëŸ¬', 'ì–´ë¦¬ë‘¥ì ˆ', 'ê¹œì§',
                    'ë†€ë€', 'ì¶©ê²©', 'ê²½ì•…'],

            'ì‹«ë‹¤': ['ì‹«ì–´', 'ì—­ê²¨', 'í˜ì˜¤', 'ë³„ë¡œ', 'ì•ˆì¢‹', 'ì§œì¦',
                   'ì‹«ë‹¤', 'ì—­ê²¹', 'í˜ì˜¤ìŠ¤ëŸ¬', 'ê¼´ë³´ê¸°ì‹«', 'ì§€ê²¨ì›Œ',
                   'ì§ˆë¦°', 'ì§€ì¹œ', 'í”¼ê³¤'],

            'ê°ì‚¬í•˜ë‹¤': ['ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ë‹¤í–‰', 'ê³ ë§™ë‹¤', 'ê°ì‚¬í•´', 'ê³ ë§ˆìš´',
                     'ê°ì‚¬ë“œë ¤', 'ë„ì›€', 'ê³ ë§ˆì› ', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'ê³ ë§ˆì›Œìš”',
                     'ë“ ë“ ', 'ì‘ì›', 'ë¯¿ì–´'],

            'í¸ì•ˆí•˜ë‹¤': ['í¸ì•ˆ', 'ì•ˆì •', 'í‰ì˜¨', 'ì—¬ìœ ', 'ë¦´ë ‰ìŠ¤', 'ì°¨ë¶„',
                     'ì•ˆë½', 'í‰í™”', 'ëŠê¸‹', 'ì•ˆì‹¬', 'í¸í•´', 'ê°€ë²¼ìš´'],

            'ìì‹ í•˜ë‹¤': ['ìì‹ ', 'í™•ì‹ ', 'ìë¶€ì‹¬', 'ìë‘', 'ë‹¹ë‹¹', 'ë¿Œë“¯',
                     'ìì‹ ìˆ', 'í™•ì‹ í•´', 'ìë¶€', 'ë‹¹ë‹¹í•´', 'ëŠ˜ê³ ', 'ëŠ˜ì–´',
                     'ë°œì „', 'ì„±ì¥', 'ì§„ì „', 'í–¥ìƒ', 'ë‚˜ì•„', 'ì¢‹ì•„']
        }

        # ğŸ”¥ ìƒí™© í‚¤ì›Œë“œ ëŒ€í­ í™•ì¥
        self.situation_keywords = {
            'ì§ì¥': ['íšŒì‚¬', 'ì§ì¥', 'ìƒì‚¬', 'ë™ë£Œ', 'ì—…ë¬´', 'ì¼', 'ê·¼ë¬´', 'ì§ì¥ì¸', 'íšŒì‚¬ì›',
                   'ë§‰ë‚´', 'íŒ€', 'í”„ë¡œì íŠ¸', 'íšŒì˜', 'ì•¼ê·¼', 'í‡´ì‚¬', 'ì´ì§'],
            'ì—°ì• ': ['ì—°ì¸', 'ë‚¨ì¹œ', 'ì—¬ì¹œ', 'ì• ì¸', 'ë°ì´íŠ¸', 'ì‚¬ë‘', 'í—¤ì–´ì ¸', 'ì´ë³„',
                   'ì»¤í”Œ', 'ë§Œë‚¨', 'ê²°í˜¼', 'ì—°ì• '],
            'ëˆ': ['ëˆ', 'ì›”ê¸‰', 'ê¸‰ì—¬', 'ì§€ì¶œ', 'ì†Œë¹„', 'ë¹„ìš©', 'ê²½ì œ', 'ê¹ì˜€', 'ì¤„ì–´',
                  'ë³´ë„ˆìŠ¤', 'ìƒí™œë¹„', 'ë¬¼ê°€', 'ì ˆì•½', 'ê¸ˆì „'],
            'ì¸ê°„ê´€ê³„': ['ì¹œêµ¬', 'ì‚¬ëŒ', 'ê´€ê³„', 'ë§Œë‚¨', 'ì†Œí†µ', 'ê°€ì¡±', 'ë¶€ëª¨', 'í˜•ì œ',
                     'ë™ìƒ', 'ì–¸ë‹ˆ', 'ì˜¤ë¹ ', 'ëˆ„ë‚˜', 'í˜‘ì—…', 'íŒ€ì›'],
            'ìŠ¤íŠ¸ë ˆìŠ¤': ['ìŠ¤íŠ¸ë ˆìŠ¤', 'í”¼ê³¤', 'í˜ë“¤', 'ì§€ì³', 'ë¶€ë‹´', 'ì••ë°•', 'ê³ ë¯¼'],
            'ì¶•í•˜': ['ì¶•í•˜', 'ìƒì¼', 'ìŠ¹ì§„', 'ì„±ê³µ', 'í•©ê²©', 'ê²°í˜¼', 'ê¸°ë…ì¼'],
            'ì¡°ì–¸': ['ì¡°ì–¸', 'ìƒë‹´', 'ë„ì›€', 'ì¶©ê³ ', 'ì‘ì›', 'ì§€ì§€'],
            'ì—…ë¬´': ['ì—…ë¬´', 'ì¼', 'í”„ë¡œì íŠ¸', 'íšŒì˜', 'ê³¼ì œ', 'ì‘ì—…', 'ê°œë°œ', 'ê³„íš'],
            'ê°œì¸ì ': ['ê°œì¸', 'í˜¼ì', 'ë‚˜ë§Œ', 'ë‚´ê°€', 'ìŠ¤ìŠ¤ë¡œ', 'ìì‹ ', 'ë³¸ì¸',
                    'ë°°ìš°', 'í•™ìŠµ', 'ê³µë¶€', 'ì‹œí—˜', 'ì´ì‚¬', 'ê±´ê°•', 'ìš´ë™', 'ì·¨ë¯¸',
                    'ì„±ì¥', 'ë°œì „', 'ê¸°ìˆ ', 'ëŠ¥ë ¥', 'ì‹¤ë ¥', 'ìƒˆë¡œìš´', 'ë„ì‹œ', 'ë³€í™”']
        }

    def analyze_text_features(self, text):
        """í–¥ìƒëœ í…ìŠ¤íŠ¸ ë¶„ì„ - ë” ì •í™•í•œ ë§¤ì¹­"""
        detected_emotions = []
        detected_situations = []

        try:
            print(f"[DEBUG] ë¶„ì„ í…ìŠ¤íŠ¸: '{text}'")

            # ê°ì • í‚¤ì›Œë“œ ê²€ì¶œ (ê°œì„ ëœ ë¡œì§)
            for emotion, keywords in self.emotion_keywords.items():
                found = False
                for keyword in keywords:
                    if keyword in text:
                        detected_emotions.append(emotion)
                        print(f"[DEBUG] ê°ì • '{emotion}' ë§¤ì¹­: '{keyword}' in '{text}'")
                        found = True
                        break
                if found:
                    continue

            # ìƒí™© í‚¤ì›Œë“œ ê²€ì¶œ (ê°œì„ ëœ ë¡œì§)
            for situation, keywords in self.situation_keywords.items():
                found = False
                for keyword in keywords:
                    if keyword in text:
                        detected_situations.append(situation)
                        print(f"[DEBUG] ìƒí™© '{situation}' ë§¤ì¹­: '{keyword}' in '{text}'")
                        found = True
                        break
                if found:
                    continue

            # ğŸ”¥ ë³µí•© ê°ì • ì²˜ë¦¬ ì¶”ê°€
            detected_emotions = self.handle_complex_emotions(text, detected_emotions)

            print(f"[DEBUG] ìµœì¢… ë¶„ì„ ê²°ê³¼ - ê°ì •: {detected_emotions}, ìƒí™©: {detected_situations}")
            return detected_emotions, detected_situations

        except Exception as e:
            print(f"[!] í…ìŠ¤íŠ¸ ë¶„ì„ ì˜ˆì™¸: {e}")
            return [], []

    def handle_complex_emotions(self, text, current_emotions):
        """ë³µí•© ê°ì • ì²˜ë¦¬"""
        # ë³µí•© ê°ì • íŒ¨í„´ ë§¤ì¹­
        complex_patterns = {
            'ê¸°ì˜ë‹¤': ['ì„¤ë ˆ', 'ê¸°ëŒ€', 'ìƒˆë¡œìš´.*ê¸°ëŒ€', 'ì„±ê³µ.*ê¸°ë»', 'í•©ê²©.*ê¸°ë»'],
            'ë¬´ì„­ë‹¤': ['ê±±ì •.*ë¼', 'ë¶ˆì•ˆ.*í•´', '.*í•˜ì§€ë§Œ.*ê±±ì •', '.*ë©´ì„œë„.*ë¶ˆì•ˆ'],
            'ìŠ¬í”„ë‹¤': ['ì‹¤ë§.*ìŠ¤ëŸ¬', 'ì•ˆ.*ì¢‹ì•„ì„œ.*ì‹¤ë§', 'ìƒê°ë³´ë‹¤.*ì•ˆ.*ì¢‹'],
            'ìì‹ í•˜ë‹¤': ['ëŠ˜ê³ .*ìˆ', 'ì¡°ê¸ˆì”©.*ëŠ˜', 'ë°œì „.*í•˜', 'ì„±ì¥.*í•˜']
        }

        import re
        for emotion, patterns in complex_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    if emotion not in current_emotions:
                        current_emotions.append(emotion)
                        print(f"[DEBUG] ë³µí•© ê°ì • ë§¤ì¹­: '{emotion}' by pattern '{pattern}'")

        return current_emotions

    def detect_negative_context(self, text):
        """ë¶€ì •ì  ë§¥ë½ ê°ì§€"""
        negative_indicators = [
            'ê¹ì˜€', 'ì¤„ì–´', 'ì‹¤íŒ¨', 'ë§í–ˆ', 'ì•ˆë¼', 'ë¬¸ì œ', 'í˜ë“¤',
            'ì–´ë ¤ì›Œ', 'ëª»í•˜ê² ', 'ì‹«ì–´', 'ë‚˜ë¹ ', 'ìµœì•…', 'ë³„ë¡œ',
            'ê±°ìŠ¬ë ¤', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í”¼ê³¤', 'ì§€ì³', 'í˜ë“¤ì–´', 'ë¶„í•˜ê³ ', 'ì„­ì„­'
        ]
        return any(indicator in text for indicator in negative_indicators)

    def find_metadata_by_filename(self, filename):
        """íŒŒì¼ëª…ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì°¾ê¸°"""
        for item in self.metadata:
            if item['filename'] == filename:
                return item
        return None

    def calculate_metadata_bonus(self, text_emotions, text_situations, image_filename, text):
        """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê³„ì‚° - ì™„ì „íˆ ìˆ˜ì •"""
        try:
            metadata = self.find_metadata_by_filename(image_filename)
            if not metadata:
                print(f"[DEBUG] ë©”íƒ€ë°ì´í„° ì—†ìŒ: {image_filename}")
                return 1.0

            bonus = 1.0

            # ë¶€ì •ì  ë§¥ë½ì—ì„œ ê¸°ì¨ ì´ë¯¸ì§€ íŒ¨ë„í‹°
            if self.detect_negative_context(text) and metadata.get('category') == 'ê¸°ì¨':
                bonus *= 0.2

            # 1. ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
            category = metadata.get('category', '')
            subcategory = metadata.get('subcategory', '')

            for emotion in text_emotions:
                if emotion == 'ê¸°ì˜ë‹¤' and category == 'ê¸°ì¨':
                    bonus += 0.8
                elif emotion == 'ìŠ¬í”„ë‹¤' and category == 'ìŠ¬í””':
                    bonus += 0.8
                elif emotion == 'í™”ë‚˜ë‹¤' and category in ['ë¶„ë…¸', 'ë‹¹í™©']:
                    bonus += 0.8
                elif emotion == 'ë¶ˆì•ˆí•˜ë‹¤' and category == 'ë¶ˆì•ˆ':
                    bonus += 0.8
                elif emotion == 'ê°ì‚¬í•˜ë‹¤' and subcategory == 'ê°ì‚¬í•˜ëŠ”':
                    bonus += 0.6
                elif emotion == 'ìì‹ í•˜ë‹¤' and subcategory == 'ìì‹ í•˜ëŠ”':
                    bonus += 0.6

            # 2. íƒœê·¸ ë§¤ì¹­
            tags = metadata.get('tags', [])
            for emotion in text_emotions:
                emotion_base = emotion.replace('ë‹¤', '')
                for tag in tags:
                    if emotion_base in tag or tag in emotion:
                        bonus += 0.3
                        break

            # 3. ì‚¬ìš© ë§¥ë½ ë§¤ì¹­
            usage_context = metadata.get('usage_context', [])
            for situation in text_situations:
                if situation in usage_context:
                    bonus += 0.4

            # 4. í…ìŠ¤íŠ¸ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
            description = metadata.get('text_description', '').lower()
            for emotion in text_emotions:
                if emotion.replace('ë‹¤', '') in description:
                    bonus += 0.2

            # 5. ì§ì ‘ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­
            text_words = text.replace('.', ' ').replace(',', ' ').split()
            for word in text_words:
                if len(word) > 1 and word in description:
                    bonus += 0.15
                    break

            return min(bonus, 3.0)

        except Exception as e:
            print(f"[!] ë³´ë„ˆìŠ¤ ê³„ì‚° ì˜ˆì™¸ ({image_filename}): {e}")
            return 1.0  # ê¸°ë³¸ê°’ ë°˜í™˜

    def find_best_match_hybrid(self, hybrid_encoder, text, image_embs, image_files):
        """í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ìµœì  ë§¤ì¹˜ ì°¾ê¸° - ì•ˆì „í™” ë²„ì „"""

        # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
        combined_similarities = None
        dual_similarities = None
        kobert_sims = None
        clip_sims = None

        try:
            print(f"[DEBUG] ì´ë¯¸ì§€ ì„ë² ë”© ì°¨ì›: {image_embs.shape}")

            # ë°©ë²• 1: ê²°í•©ëœ ì„ë² ë”© ì‚¬ìš©
            try:
                combined_text_emb = hybrid_encoder.get_text_embedding(text)
                print(f"[DEBUG] ê²°í•© í…ìŠ¤íŠ¸ ì„ë² ë”© ì°¨ì›: {len(combined_text_emb)}")
                combined_similarities = cosine_similarity([combined_text_emb], image_embs)[0]
                print("[DEBUG] ê²°í•© ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚° ì„±ê³µ")
            except Exception as e:
                print(f"[!] ê²°í•© ì„ë² ë”© ì‹¤íŒ¨: {e}")

            # ë°©ë²• 2: ê°ê° ê³„ì‚° í›„ ê²°í•©
            try:
                dual_similarities, kobert_sims, clip_sims = hybrid_encoder.get_dual_similarities(text, image_embs)
                print("[DEBUG] ë“€ì–¼ ìœ ì‚¬ë„ ê³„ì‚° ì„±ê³µ")
            except Exception as e:
                print(f"[!] ë“€ì–¼ ìœ ì‚¬ë„ ì‹¤íŒ¨: {e}")

            # ìµœì¢… ìœ ì‚¬ë„ ê²°ì •
            if combined_similarities is not None and dual_similarities is not None:
                final_similarities = 0.7 * combined_similarities + 0.3 * dual_similarities
                print("[DEBUG] í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ì‚¬ìš©")
            elif combined_similarities is not None:
                final_similarities = combined_similarities
                print("[DEBUG] ê²°í•© ì„ë² ë”©ë§Œ ì‚¬ìš©")
            elif dual_similarities is not None:
                final_similarities = dual_similarities
                print("[DEBUG] ë“€ì–¼ ìœ ì‚¬ë„ë§Œ ì‚¬ìš©")
            else:
                print("[!] ëª¨ë“  ë°©ì‹ ì‹¤íŒ¨, CLIP í´ë°± ì‚¬ìš©")
                clip_text_emb = hybrid_encoder.get_clip_text_embedding(text)
                final_similarities = cosine_similarity([clip_text_emb], image_embs)[0]
                kobert_sims = np.zeros_like(final_similarities)
                clip_sims = final_similarities

        except Exception as e:
            print(f"[!] ì „ì²´ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            try:
                clip_text_emb = hybrid_encoder.clip_encoder.get_text_embedding(text)
                final_similarities = cosine_similarity([clip_text_emb], image_embs)[0]
                kobert_sims = np.zeros_like(final_similarities)
                clip_sims = final_similarities
            except Exception as final_e:
                print(f"[!] ìµœì¢… í´ë°±ë„ ì‹¤íŒ¨: {final_e}")
                final_similarities = np.random.random(len(image_files))
                kobert_sims = np.zeros_like(final_similarities)
                clip_sims = np.zeros_like(final_similarities)

        # í…ìŠ¤íŠ¸ ë¶„ì„ (ë°˜ë“œì‹œ íŠœí”Œ ë°˜í™˜ ë³´ì¥)
        result = self.analyze_text_features(text)
        if result is None or len(result) != 2:
            text_emotions, text_situations = [], []
        else:
            text_emotions, text_situations = result

        # ë¶€ì •ì  ë§¥ë½ ë³´ì •
        try:
            if self.detect_negative_context(text):
                for i, img_file in enumerate(image_files):
                    metadata = self.find_metadata_by_filename(os.path.basename(img_file))
                    if metadata and metadata.get('category', '') == 'ê¸°ì¨':
                        final_similarities[i] *= 0.2
        except Exception as e:
            print(f"[!] ë¶€ì •ì  ë§¥ë½ ë³´ì • ì‹¤íŒ¨: {e}")

        # ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤ ì ìš© (ì•ˆì „í•˜ê²Œ)
        enhanced_similarities = []
        for i, sim in enumerate(final_similarities):
            try:
                image_filename = os.path.basename(image_files[i])
                bonus = self.calculate_metadata_bonus(text_emotions, text_situations, image_filename, text)
                if bonus is None:
                    bonus = 1.0
                enhanced_score = sim * bonus
                enhanced_similarities.append(enhanced_score)
            except Exception as e:
                print(f"[!] ë³´ë„ˆìŠ¤ ê³„ì‚° ì‹¤íŒ¨ (ì´ë¯¸ì§€ {i}): {e}")
                enhanced_similarities.append(sim)  # ì›ë³¸ ìœ ì‚¬ë„ ì‚¬ìš©

        enhanced_similarities = np.array(enhanced_similarities)

        # ìµœê³  ë§¤ì¹˜ ì°¾ê¸°
        best_idx = np.argmax(enhanced_similarities)
        best_score = enhanced_similarities[best_idx]

        # Top 5 ê²°ê³¼
        top_5_indices = np.argsort(enhanced_similarities)[-5:][::-1]
        top_5_results = []
        for i in top_5_indices:
            try:
                image_filename = os.path.basename(image_files[i])
                metadata = self.find_metadata_by_filename(image_filename)

                result_info = {
                    'filename': image_filename,
                    'score': enhanced_similarities[i],
                    'combined_sim': combined_similarities[i] if combined_similarities is not None else 0,
                    'dual_sim': dual_similarities[i] if dual_similarities is not None else 0,
                    'kobert_sim': kobert_sims[i] if kobert_sims is not None else 0,
                    'clip_sim': clip_sims[i] if clip_sims is not None else 0,
                    'category': metadata.get('category', 'ì•Œ ìˆ˜ ì—†ìŒ') if metadata else 'ì•Œ ìˆ˜ ì—†ìŒ',
                    'subcategory': metadata.get('subcategory', 'ì•Œ ìˆ˜ ì—†ìŒ') if metadata else 'ì•Œ ìˆ˜ ì—†ìŒ'
                }
                top_5_results.append(result_info)
            except Exception as e:
                print(f"[!] Top 5 ê²°ê³¼ ìƒì„± ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")

        return best_idx, best_score, top_5_results, text_emotions, text_situations


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # ë§¤ì²˜ í…ŒìŠ¤íŠ¸
    matcher = HybridMatcher()

    # í…ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸
    test_texts = [
        "ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„!",
        "ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
        "ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤˜ì„œ ê°ì‚¬í•´."
    ]

    for text in test_texts:
        emotions, situations = matcher.analyze_text_features(text)
        print(f"\ní…ìŠ¤íŠ¸: {text}")
        print(f"ê°ì •: {emotions}, ìƒí™©: {situations}")