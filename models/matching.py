from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
import os


class HybridMatcher:
    def __init__(self, metadata_file="data/enhanced_image_metadata.json"):
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = []
        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                print(f"[*] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.metadata)}ê°œ ì´ë¯¸ì§€")
            except Exception as e:
                print(f"[!] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        # í™•ì¥ëœ ê°ì • í‚¤ì›Œë“œ
        self.emotion_keywords = {
            'í™”ë‚˜ë‹¤': ['í™”', 'ì§œì¦', 'ë¹¡', 'ë¶„ë…¸', 'ì—´ë°›', 'ê¸°ë§‰', 'ë¶„í•˜ë‹¤', 'ì„±ë‚˜ë‹¤',
                    'ë¶„í•´', 'ì•½ì˜¤ë¥´', 'ë¹¡ì¹˜', 'ì—´ë¶ˆë‚˜', 'ì†í„°ì ¸', 'ê³¨ì¹˜',
                    'ê±°ìŠ¬ë ¤', 'ì§œì¦ë‚˜', 'í™”ë‚˜', 'ì—´ë°›ì•„', 'ë¶„í•˜ê³ ', 'ì„­ì„­í•´', 'ì–µìš¸',
                    'ì–´ì´ì—†', 'ë‹µë‹µ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'ë¹¡ì³', 'ì—´ë‚˜', 'ë¹ˆì •', 'ì•½ì˜¬ë¼'],

            'ìŠ¬í”„ë‹¤': ['ìŠ¬í”ˆ', 'ìš°ìš¸', 'ì†ìƒ', 'ì„œëŸ½', 'ëˆˆë¬¼', 'ìš¸ê³ ', 'ì„œê¸€',
                    'ìŠ¬í¼', 'ìš°ìš¸í•´', 'ì„œëŸ¬ì›Œ', 'ëˆˆë¬¼ë‚˜', 'ë§ˆìŒì•„í”ˆ', 'ê°€ìŠ´ì•„í”ˆ',
                    'ì“¸ì“¸', 'ì™¸ë¡œì›Œ', 'í—ˆì „', 'í—¤ì–´ì ¸', 'ì´ë³„', 'ê·¸ë¦¬ì›Œ',
                    'ì‹¤ë§', 'ì‹¤ë§ìŠ¤ëŸ¬', 'ì„œìš´', 'ì•ˆíƒ€ê¹Œ', 'ê°€ìŠ´', 'ë§ˆìŒ', 'ìƒì²˜'],

            'ê¸°ì˜ë‹¤': ['ê¸°ìœ', 'í–‰ë³µ', 'ì¢‹ë‹¤', 'ì‹ ë‚˜', 'ì¦ê±°', 'ë§Œì¡±', 'ê¸°ë»',
                    'ì¢‹ì•„', 'í–‰ë³µí•´', 'ê¸°ë¶„ì¢‹', 'ì‹ ì´ë‚˜', 'ì¦ê±°ì›Œ', 'ë§Œì¡±í•´',
                    'ì„±ê³µ', 'ìŠ¹ì§„', 'í•©ê²©', 'ì¶•í•˜', 'ê¸°ë»ìš”', 'ì¢‹ë„¤', 'ìµœê³ ',
                    'ì„¤ë ˆ', 'ì„¤ë ˜', 'ë“¤ëœ¨', 'ê¸°ëŒ€', 'í™˜ìƒ', 'ì™„ë²½', 'ë©‹ì ¸'],

            'ë¬´ì„­ë‹¤': ['ë¬´ì„œ', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ë‘ë ¤', 'ë¬´ì„œì›Œ', 'ê±±ì •ë˜',
                    'ë¶ˆì•ˆí•´', 'ë‘ë ¤ì›Œ', 'ë¬´ì‹œë¬´ì‹œ', 'ì‹¬ë€', 'ì¡°ë§ˆì¡°ë§ˆ',
                    'ê±±ì •ìŠ¤ëŸ¬', 'ì—¼ë ¤', 'ê·¼ì‹¬', 'ìš°ë ¤', 'ë¬´ì„œìš´'],

            'ë†€ëë‹¤': ['ë†€ë¼', 'ì‹ ê¸°', 'ëŒ€ë°•', 'í—', 'ì™€', 'ë‹¹í™©', 'ì–´ì©Œì§€',
                    'ë†€ë¼ì›Œ', 'ì‹ ê¸°í•´', 'ë‹¹í™©ìŠ¤ëŸ¬', 'ì–´ë¦¬ë‘¥ì ˆ', 'ê¹œì§',
                    'ë†€ë€', 'ì¶©ê²©', 'ê²½ì•…'],

            'ì‹«ë‹¤': ['ì‹«ì–´', 'ì—­ê²¨', 'í˜ì˜¤', 'ë³„ë¡œ', 'ì•ˆì¢‹', 'ì§œì¦',
                   'ì‹«ë‹¤', 'ì—­ê²¹', 'í˜ì˜¤ìŠ¤ëŸ¬', 'ê¼´ë³´ê¸°ì‹«', 'ì§€ê²¨ì›Œ',
                   'ì§ˆë¦°', 'ì§€ì¹œ', 'í”¼ê³¤'],

            'ê°ì‚¬í•˜ë‹¤': ['ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ë‹¤í–‰', 'ê³ ë§™ë‹¤', 'ê°ì‚¬í•´', 'ê³ ë§ˆìš´',
                     'ê°ì‚¬ë“œë ¤', 'ë„ì›€', 'ê³ ë§ˆì› ', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'ê³ ë§ˆì›Œìš”',
                     'ë“ ë“ ', 'ì‘ì›', 'ë¯¿ì–´'],

            'í¸ì•ˆí•˜ë‹¤': ['í¸ì•ˆ', 'ì•ˆì •', 'í‰ì˜¨', 'ì—¬ìœ ', 'ë¦´ë ‰ìŠ¤', 'ì°¨ë¶„',
                     'ì•ˆë½', 'í‰í™”', 'ëŠê¸‹', 'ì•ˆì‹¬', 'í¸í•´', 'ê°€ë²¼ìš´'],

            'ìì‹ í•˜ë‹¤': ['ìì‹ ', 'í™•ì‹ ', 'ìë¶€ì‹¬', 'ìë‘', 'ë‹¹ë‹¹', 'ë¿Œë“¯',
                     'ìì‹ ìˆ', 'í™•ì‹ í•´', 'ìë¶€', 'ë‹¹ë‹¹í•´', 'ëŠ˜ê³ ', 'ëŠ˜ì–´',
                     'ë°œì „', 'ì„±ì¥', 'ì§„ì „', 'í–¥ìƒ', 'ë‚˜ì•„', 'ì¢‹ì•„']
        }

        # ìƒí™© í‚¤ì›Œë“œ í™•ì¥
        self.situation_keywords = {
            'ì§ì¥': ['íšŒì‚¬', 'ì§ì¥', 'ìƒì‚¬', 'ë™ë£Œ', 'ì—…ë¬´', 'ì¼', 'ê·¼ë¬´', 'ì§ì¥ì¸', 'íšŒì‚¬ì›',
                   'ë§‰ë‚´', 'íŒ€', 'í”„ë¡œì íŠ¸', 'íšŒì˜', 'ì•¼ê·¼', 'í‡´ì‚¬', 'ì´ì§'],
            'ì—°ì• ': ['ì—°ì¸', 'ë‚¨ì¹œ', 'ì—¬ì¹œ', 'ì• ì¸', 'ë°ì´íŠ¸', 'ì‚¬ë‘', 'í—¤ì–´ì ¸', 'ì´ë³„',
                   'ì»¤í”Œ', 'ë§Œë‚¨', 'ê²°í˜¼', 'ì—°ì• '],
            'ëˆ': ['ëˆ', 'ì›”ê¸‰', 'ê¸‰ì—¬', 'ì§€ì¶œ', 'ì†Œë¹„', 'ë¹„ìš©', 'ê²½ì œ', 'ê¹ì˜€', 'ì¤„ì–´',
                  'ë³´ë„ˆìŠ¤', 'ìƒí™œë¹„', 'ë¬¼ê°€', 'ì ˆì•½', 'ê¸ˆì „'],
            'ì¸ê°„ê´€ê³„': ['ì¹œêµ¬', 'ì‚¬ëŒ', 'ê´€ê³„', 'ë§Œë‚¨', 'ì†Œí†µ', 'ê°€ì¡±', 'ë¶€ëª¨', 'í˜•ì œ',
                     'ë™ìƒ', 'ì–¸ë‹ˆ', 'ì˜¤ë¹ ', 'ëˆ„ë‚˜', 'í˜‘ì—…', 'íŒ€ì›'],
            'ìŠ¤íŠ¸ë ˆìŠ¤': ['ìŠ¤íŠ¸ë ˆìŠ¤', 'í”¼ê³¤', 'í˜ë“¤', 'ì§€ì³', 'ë¶€ë‹´', 'ì••ë°•', 'ê³ ë¯¼'],
            'ì¶•í•˜': ['ì¶•í•˜', 'ìƒì¼', 'ìŠ¹ì§„', 'ì„±ê³µ', 'í•©ê²©', 'ê²°í˜¼', 'ê¸°ë…ì¼'],
            'ì¡°ì–¸': ['ì¡°ì–¸', 'ìƒë‹´', 'ë„ì›€', 'ì¶©ê³ ', 'ì‘ì›', 'ì§€ì§€'],
            'ì—…ë¬´': ['ì—…ë¬´', 'ì¼', 'í”„ë¡œì íŠ¸', 'íšŒì˜', 'ê³¼ì œ', 'ì‘ì—…', 'ê°œë°œ', 'ê³„íš'],
            'ê°œì¸ì ': ['ê°œì¸', 'í˜¼ì', 'ë‚˜ë§Œ', 'ë‚´ê°€', 'ìŠ¤ìŠ¤ë¡œ', 'ìì‹ ', 'ë³¸ì¸',
                    'ë°°ìš°', 'í•™ìŠµ', 'ê³µë¶€', 'ì‹œí—˜', 'ì´ì‚¬', 'ê±´ê°•', 'ìš´ë™', 'ì·¨ë¯¸',
                    'ì„±ì¥', 'ë°œì „', 'ê¸°ìˆ ', 'ëŠ¥ë ¥', 'ì‹¤ë ¥', 'ìƒˆë¡œìš´', 'ë„ì‹œ', 'ë³€í™”']
        }

    def analyze_emotions(self, text):
        """ê°ì • ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        if not text:
            return []

        detected_emotions = []
        text_lower = text.lower()

        for emotion, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    detected_emotions.append(emotion)
                    break  # ê°ì •ë‹¹ í•œ ë²ˆë§Œ ì¶”ê°€

        return detected_emotions

    def analyze_situations(self, text):
        """ìƒí™© ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        if not text:
            return []

        detected_situations = []
        text_lower = text.lower()

        for situation, keywords in self.situation_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    detected_situations.append(situation)
                    break  # ìƒí™©ë‹¹ í•œ ë²ˆë§Œ ì¶”ê°€

        return detected_situations

    def analyze_text_features(self, text):
        """í–¥ìƒëœ í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            detected_emotions = self.analyze_emotions(text)
            detected_situations = self.analyze_situations(text)

            return detected_emotions, detected_situations

        except Exception as e:
            print(f"[!] í…ìŠ¤íŠ¸ ë¶„ì„ ì˜ˆì™¸: {e}")
            return [], []

    def detect_negative_context(self, text):
        """ë¶€ì •ì  ë§¥ë½ ê°ì§€"""
        negative_indicators = [
            'ê¹ì˜€', 'ì¤„ì–´', 'ì‹¤íŒ¨', 'ë§í–ˆ', 'ì•ˆë¼', 'ë¬¸ì œ', 'í˜ë“¤',
            'ì–´ë ¤ì›Œ', 'ëª»í•˜ê² ', 'ì‹«ì–´', 'ë‚˜ë¹ ', 'ìµœì•…', 'ë³„ë¡œ',
            'ê±°ìŠ¬ë ¤', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í”¼ê³¤', 'ì§€ì³', 'í˜ë“¤ì–´', 'ë¶„í•˜ê³ ', 'ì„­ì„­'
        ]
        return any(indicator in text for indicator in negative_indicators)

    def find_metadata_by_filename(self, filename):
        """íŒŒì¼ëª…ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì°¾ê¸°"""
        for item in self.metadata:
            if item['filename'] == filename:
                return item
        return None

    def calculate_metadata_bonus(self, text_emotions, text_situations, image_filename, text):
        """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê³„ì‚°"""
        try:
            metadata = self.find_metadata_by_filename(image_filename)
            if not metadata:
                return 1.0

            bonus = 1.0

            # ë¶€ì •ì  ë§¥ë½ì—ì„œ ê¸°ì¨ ì´ë¯¸ì§€ íŒ¨ë„í‹°
            if self.detect_negative_context(text) and metadata.get('category') == 'ê¸°ì¨':
                bonus *= 0.2

            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
            category = metadata.get('category', '')
            subcategory = metadata.get('subcategory', '')

            for emotion in text_emotions:
                if emotion == 'ê¸°ì˜ë‹¤' and category == 'ê¸°ì¨':
                    bonus += 0.8
                elif emotion == 'ìŠ¬í”„ë‹¤' and category == 'ìŠ¬í””':
                    bonus += 0.8
                elif emotion == 'í™”ë‚˜ë‹¤' and category in ['ë¶„ë…¸', 'ë‹¹í™©']:
                    bonus += 0.8
                elif emotion == 'ë¶ˆì•ˆí•˜ë‹¤' and category == 'ë¶ˆì•ˆ':
                    bonus += 0.8
                elif emotion == 'ê°ì‚¬í•˜ë‹¤' and subcategory == 'ê°ì‚¬í•˜ëŠ”':
                    bonus += 0.6
                elif emotion == 'ìì‹ í•˜ë‹¤' and subcategory == 'ìì‹ í•˜ëŠ”':
                    bonus += 0.6

            return min(bonus, 3.0)

        except Exception as e:
            print(f"[!] ë³´ë„ˆìŠ¤ ê³„ì‚° ì˜ˆì™¸ ({image_filename}): {e}")
            return 1.0

    def find_best_match_hybrid(self, encoder, text, image_embs, image_files):
        """
        âœ… ìˆ˜ì •ëœ í•˜ì´ë¸Œë¦¬ë“œ ë§¤ì¹­ - CLIPEncoderì™€ í˜¸í™˜

        Args:
            encoder: CLIPEncoder ë˜ëŠ” HybridEncoder ì¸ìŠ¤í„´ìŠ¤
            text: ì…ë ¥ í…ìŠ¤íŠ¸ (ë¬¸ìì—´)
            image_embs: ì´ë¯¸ì§€ ì„ë² ë”© ë°°ì—´
            image_files: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"[DEBUG] ì´ë¯¸ì§€ ì„ë² ë”© ì°¨ì›: {image_embs.shape}")

            # ğŸ”§ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ë¬¸ìì—´ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜)
            if hasattr(encoder, 'get_text_embedding'):
                # CLIPEncoder ì‚¬ìš©
                text_emb = encoder.get_text_embedding(text)
                print(f"[DEBUG] CLIP í…ìŠ¤íŠ¸ ì„ë² ë”© ì°¨ì›: {len(text_emb)}")

                # ë“€ì–¼ ìœ ì‚¬ë„ ì‹œë„ (ìˆìœ¼ë©´)
                if hasattr(encoder, 'get_dual_similarities'):
                    try:
                        # ê°ì •/ìƒí™© ë¶„ì„
                        emotions, situations = self.analyze_text_features(text)

                        # âœ… ì„ë² ë”©ì„ ì „ë‹¬ (ë¬¸ìì—´ì´ ì•„ë‹˜!)
                        combined_similarities, text_similarities, weighted_similarities = encoder.get_dual_similarities(
                            text_emb, image_embs, emotions, situations
                        )
                        print("[DEBUG] ë“€ì–¼ ìœ ì‚¬ë„ ê³„ì‚° ì„±ê³µ")
                        final_similarities = combined_similarities

                    except Exception as e:
                        print(f"[!] ë“€ì–¼ ìœ ì‚¬ë„ ì‹¤íŒ¨: {e}")
                        # ê¸°ë³¸ ìœ ì‚¬ë„ ê³„ì‚°
                        final_similarities = cosine_similarity([text_emb], image_embs)[0]

                else:
                    # ê¸°ë³¸ ìœ ì‚¬ë„ ê³„ì‚°
                    final_similarities = cosine_similarity([text_emb], image_embs)[0]

            elif hasattr(encoder, 'get_dual_similarities'):
                # HybridEncoder ì‚¬ìš©
                emotions, situations = self.analyze_text_features(text)
                final_similarities, _, _ = encoder.get_dual_similarities(text, image_embs)
                print("[DEBUG] HybridEncoder ë“€ì–¼ ìœ ì‚¬ë„ ì‚¬ìš©")

            else:
                # í´ë°±: ê¸°ë³¸ CLIP ë°©ì‹
                if hasattr(encoder, 'clip_encoder'):
                    text_emb = encoder.clip_encoder.get_text_embedding(text)
                else:
                    text_emb = encoder.encode_text(text)  # ë‹¤ë¥¸ ì¸í„°í˜ì´ìŠ¤ ì‹œë„

                final_similarities = cosine_similarity([text_emb], image_embs)[0]
                print("[DEBUG] í´ë°± ìœ ì‚¬ë„ ê³„ì‚° ì‚¬ìš©")

            # í…ìŠ¤íŠ¸ ë¶„ì„ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
            emotions, situations = self.analyze_text_features(text)

            # ë¶€ì •ì  ë§¥ë½ ë³´ì •
            if self.detect_negative_context(text):
                for i, img_file in enumerate(image_files):
                    metadata = self.find_metadata_by_filename(os.path.basename(img_file))
                    if metadata and metadata.get('category', '') == 'ê¸°ì¨':
                        final_similarities[i] *= 0.2

            # ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤ ì ìš©
            enhanced_similarities = []
            for i, sim in enumerate(final_similarities):
                try:
                    image_filename = os.path.basename(image_files[i])
                    bonus = self.calculate_metadata_bonus(emotions, situations, image_filename, text)
                    enhanced_score = sim * bonus
                    enhanced_similarities.append(enhanced_score)
                except Exception as e:
                    print(f"[!] ë³´ë„ˆìŠ¤ ê³„ì‚° ì‹¤íŒ¨ (ì´ë¯¸ì§€ {i}): {e}")
                    enhanced_similarities.append(sim)

            enhanced_similarities = np.array(enhanced_similarities)

            # ìµœê³  ë§¤ì¹˜ ì°¾ê¸°
            best_idx = np.argmax(enhanced_similarities)
            best_score = enhanced_similarities[best_idx]

            # Top 5 ê²°ê³¼
            top_5_indices = np.argsort(enhanced_similarities)[-5:][::-1]
            top_5_results = []

            for i in top_5_indices:
                try:
                    image_filename = os.path.basename(image_files[i])
                    metadata = self.find_metadata_by_filename(image_filename)

                    result_info = {
                        'filename': image_filename,
                        'score': float(enhanced_similarities[i]),
                        'combined_sim': float(final_similarities[i]),
                        'category': metadata.get('category', 'ì•Œ ìˆ˜ ì—†ìŒ') if metadata else 'ì•Œ ìˆ˜ ì—†ìŒ',
                        'subcategory': metadata.get('subcategory', 'ì•Œ ìˆ˜ ì—†ìŒ') if metadata else 'ì•Œ ìˆ˜ ì—†ìŒ'
                    }
                    top_5_results.append(result_info)
                except Exception as e:
                    print(f"[!] Top 5 ê²°ê³¼ ìƒì„± ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")

            return best_idx, float(best_score), top_5_results, emotions, situations

        except Exception as e:
            print(f"[!] í•˜ì´ë¸Œë¦¬ë“œ ë§¤ì¹­ ì „ì²´ ì‹¤íŒ¨: {e}")
            # ìµœì¢… í´ë°±
            return 0, 0.0, [], ["ì˜¤ë¥˜"], ["ì˜¤ë¥˜ìƒí™©"]


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # ë§¤ì²˜ í…ŒìŠ¤íŠ¸
    matcher = HybridMatcher()

    # í…ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸
    test_texts = [
        "ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„!",
        "ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
        "ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤˜ì„œ ê°ì‚¬í•´."
    ]

    for text in test_texts:
        emotions, situations = matcher.analyze_text_features(text)
        print(f"\ní…ìŠ¤íŠ¸: {text}")
        print(f"ê°ì •: {emotions}, ìƒí™©: {situations}")