import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import json


class MemeRecommendationEvaluator:
    def __init__(self, recommender, test_data):
        self.recommender = recommender
        self.test_data = test_data
        self.evaluation_results = []

    def evaluate_recommendations(self):
        """ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€"""
        correct_top1 = 0
        correct_top3 = 0
        correct_top5 = 0
        total_tests = len(self.test_data)

        emotion_accuracy = {'ë¶„ë…¸': [], 'ê¸°ì¨': [], 'ìŠ¬í””': [], 'ë¶ˆì•ˆ': []}
        situation_accuracy = {'ì§ì¥': [], 'ì§„ë¡œ': [], 'ì¸ê°„ê´€ê³„': []}

        print("[*] ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")

        for i, test_case in enumerate(self.test_data):
            if i % 10 == 0:
                print(f"  ì§„í–‰ë¥ : {i}/{total_tests}")

            # ì¶”ì²œ ì‹¤í–‰
            result = self.recommender.recommend(test_case['text'])

            # ì‹¤ì œ ì •ë‹µ ì´ë¯¸ì§€ë“¤
            expected_images = [test_case['image_filename']]

            # Top-K ì •í™•ë„ ê³„ì‚°
            top_5_images = [item['filename'] for item in result['top_5']]

            is_top1_correct = result['best_image'] in expected_images
            is_top3_correct = any(img in expected_images for img in top_5_images[:3])
            is_top5_correct = any(img in expected_images for img in top_5_images)

            if is_top1_correct:
                correct_top1 += 1
            if is_top3_correct:
                correct_top3 += 1
            if is_top5_correct:
                correct_top5 += 1

            # ê°ì •ë³„ ì •í™•ë„
            emotion = test_case['emotion']
            if emotion in emotion_accuracy:
                emotion_accuracy[emotion].append(is_top1_correct)

            # ìƒí™©ë³„ ì •í™•ë„
            for situation in test_case['situation']:
                if situation in situation_accuracy:
                    situation_accuracy[situation].append(is_top1_correct)

            # ê°œë³„ ê²°ê³¼ ì €ì¥
            self.evaluation_results.append({
                'dialogue_id': test_case['dialogue_id'],
                'text': test_case['text'][:100] + "...",
                'expected_image': test_case['image_filename'],
                'predicted_image': result['best_image'],
                'score': result['score'],
                'emotion': emotion,
                'top1_correct': is_top1_correct,
                'top3_correct': is_top3_correct,
                'top5_correct': is_top5_correct
            })

        # ì „ì²´ ì •í™•ë„ ê³„ì‚°
        accuracy_top1 = correct_top1 / total_tests
        accuracy_top3 = correct_top3 / total_tests
        accuracy_top5 = correct_top5 / total_tests

        # ê°ì •ë³„ ì •í™•ë„ ê³„ì‚°
        emotion_results = {}
        for emotion, results in emotion_accuracy.items():
            if results:
                emotion_results[emotion] = sum(results) / len(results)
            else:
                emotion_results[emotion] = 0.0

        # ìƒí™©ë³„ ì •í™•ë„ ê³„ì‚°
        situation_results = {}
        for situation, results in situation_accuracy.items():
            if results:
                situation_results[situation] = sum(results) / len(results)
            else:
                situation_results[situation] = 0.0

        return {
            'total_tests': total_tests,
            'accuracy_top1': accuracy_top1,
            'accuracy_top3': accuracy_top3,
            'accuracy_top5': accuracy_top5,
            'emotion_accuracy': emotion_results,
            'situation_accuracy': situation_results,
            'detailed_results': self.evaluation_results
        }

    def print_evaluation_report(self, results):
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
        print("=" * 60)

        print(f"ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {results['total_tests']}ê°œ")
        print(f"Top-1 ì •í™•ë„: {results['accuracy_top1']:.3f} ({results['accuracy_top1'] * 100:.1f}%)")
        print(f"Top-3 ì •í™•ë„: {results['accuracy_top3']:.3f} ({results['accuracy_top3'] * 100:.1f}%)")
        print(f"Top-5 ì •í™•ë„: {results['accuracy_top5']:.3f} ({results['accuracy_top5'] * 100:.1f}%)")

        print("\nğŸ“ˆ ê°ì •ë³„ ì •í™•ë„:")
        for emotion, accuracy in results['emotion_accuracy'].items():
            print(f"  {emotion}: {accuracy:.3f} ({accuracy * 100:.1f}%)")

        print("\nğŸ¢ ìƒí™©ë³„ ì •í™•ë„:")
        for situation, accuracy in results['situation_accuracy'].items():
            print(f"  {situation}: {accuracy:.3f} ({accuracy * 100:.1f}%)")

        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
        failed_cases = [r for r in results['detailed_results'] if not r['top1_correct']]
        if failed_cases:
            print(f"\nâŒ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ (ìƒìœ„ 5ê°œ):")
            for case in failed_cases[:5]:
                print(f"  í…ìŠ¤íŠ¸: {case['text']}")
                print(f"  ì˜ˆìƒ: {case['expected_image']}, ì˜ˆì¸¡: {case['predicted_image']}")
                print(f"  ì ìˆ˜: {case['score']:.3f}, ê°ì •: {case['emotion']}")
                print()

    def save_evaluation_results(self, results, filename="evaluation_results.json"):
        """í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"[*] í‰ê°€ ê²°ê³¼ ì €ì¥: {filename}")