import os
import warnings
from transformers import logging

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
warnings.filterwarnings("ignore")
logging.set_verbosity_error()

from models.clip_encoder import CLIPEncoder
from models.matching import HybridMatcher
from utils.data_loader import DialogueDataLoader
from utils.evaluator import MemeRecommendationEvaluator
import glob
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pandas as pd


class TrainableRecommendationSystem:
    def __init__(self, dialogue_metadata="data/converted_dialogues.json",
                 image_metadata="data/enhanced_image_metadata.json"):  # íŒŒì¼ëª… ìˆ˜ì •
        print("[*] í•™ìŠµ ê°€ëŠ¥í•œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        self.data_loader = DialogueDataLoader(dialogue_metadata, image_metadata)

        # ëª¨ë¸ ì´ˆê¸°í™”
        self.clip_encoder = CLIPEncoder()
        self.matcher = HybridMatcher(image_metadata)

        # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ
        self.load_images_from_metadata(image_metadata)

        # ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
        self.precompute_image_embeddings()

        # ì„±ëŠ¥ ì¶”ì ìš© ë³€ìˆ˜ë“¤
        self.training_history = {
            'accuracy_top1': [],
            'accuracy_top3': [],
            'accuracy_top5': [],
            'loss': [],
            'emotion_accuracy': [],
            'similarity_scores': []
        }

    def load_images_from_metadata(self, metadata_file):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ - ê°œì„ ëœ ë²„ì „"""
        self.image_files = []

        print(f"[*] ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸: {metadata_file}")

        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                print(f"[*] ë©”íƒ€ë°ì´í„°ì—ì„œ {len(metadata)}ê°œ í•­ëª© ë°œê²¬")

                for i, item in enumerate(metadata):
                    if item.get('processing_status') == 'success':
                        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
                        possible_paths = [
                            item.get('processed_path'),
                            item.get('filepath'),
                            f"data/images/{item.get('filepath', '')}",
                            f"data/images/{item.get('filename', '')}"
                        ]

                        for path in possible_paths:
                            if path and os.path.exists(path):
                                self.image_files.append(path)
                                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
                                    print(f"[DEBUG] ì´ë¯¸ì§€ ë¡œë“œ: {path}")
                                break
                        else:
                            if i < 5:  # ì²˜ìŒ 5ê°œ ì‹¤íŒ¨ë§Œ ë¡œê·¸
                                print(f"[DEBUG] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {item.get('filename', 'unknown')}")

                print(f"[*] ë©”íƒ€ë°ì´í„°ì—ì„œ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")

            except Exception as e:
                print(f"[!] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.load_images_fallback()
        else:
            print(f"[!] ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            self.load_images_fallback()

        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í´ë°± ì‹œë„
        if len(self.image_files) == 0:
            print("[!] ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë“œë¡œ ì „í™˜...")
            self.load_images_fallback()

    def load_images_fallback(self):
        """í´ë°±: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ë¡œë“œ"""
        print("[*] í´ë°± ëª¨ë“œ: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

        image_patterns = [
            "data/images/**/*.jpg",
            "data/images/**/*.png",
            "data/images/**/*.jpeg",
            "data/images/**/*.webp"
        ]

        self.image_files = []
        for pattern in image_patterns:
            found_files = glob.glob(pattern, recursive=True)
            self.image_files.extend(found_files)
            print(f"[DEBUG] íŒ¨í„´ '{pattern}'ì—ì„œ {len(found_files)}ê°œ íŒŒì¼ ë°œê²¬")

        # ì¤‘ë³µ ì œê±°
        self.image_files = list(set(self.image_files))
        print(f"[*] í´ë°± ëª¨ë“œë¡œ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ")

    def precompute_image_embeddings(self):
        """ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°"""
        if not self.image_files:
            print("[!] âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise ValueError("ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ì–´ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        print("[*] ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
        self.image_embeddings = []

        for i, img_path in enumerate(self.image_files):
            if i % 10 == 0:
                print(f"  ì§„í–‰ë¥ : {i}/{len(self.image_files)}")

            try:
                emb = self.clip_encoder.encode_image(img_path)
                self.image_embeddings.append(emb)
            except Exception as e:
                print(f"[!] ì´ë¯¸ì§€ ì„ë² ë”© ì‹¤íŒ¨: {img_path}, ì—ëŸ¬: {e}")
                # ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ëŠ” 0 ë²¡í„°ë¡œ ëŒ€ì²´
                self.image_embeddings.append(np.zeros(512))

        self.image_embeddings = np.array(self.image_embeddings)
        print("[*] âœ… ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

    def calculate_loss(self, predicted_similarities, true_image_idx):
        """Cross-entropy loss ê³„ì‚°"""
        # Softmax ì ìš©
        exp_sims = np.exp(predicted_similarities - np.max(predicted_similarities))
        softmax_probs = exp_sims / np.sum(exp_sims)

        # Cross-entropy loss
        loss = -np.log(softmax_probs[true_image_idx] + 1e-8)
        return loss

    def recommend(self, dialogue_text):
        """ëŒ€í™” í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì´ë¯¸ì§€ ì¶”ì²œ"""
        text_emb = self.clip_encoder.get_text_embedding(dialogue_text)

        best_idx, score, top_5, emotions, situations = self.matcher.find_best_match_hybrid(
            self.clip_encoder, dialogue_text, self.image_embeddings, self.image_files
        )

        return {
            'best_image': os.path.basename(self.image_files[best_idx]),
            'best_image_path': self.image_files[best_idx],
            'score': score,
            'emotions': emotions,
            'situations': situations,
            'top_5': top_5
        }

    def train_and_evaluate(self, test_size=0.2, epochs=5):
        """í•™ìŠµ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€ - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”"""
        print("\n[*] ë°ì´í„° ë¶„í•  ì¤‘...")
        train_data, test_data = self.data_loader.split_data(test_size=test_size)

        # ë°ì´í„° ê²€ì¦
        if len(train_data) == 0 and len(test_data) == 0:
            print("[!] âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë©”íƒ€ë°ì´í„° ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            print("[*] ğŸ“ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
            return self.run_simple_test()

        if len(test_data) == 0:
            print("[!] âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ë°ëª¨ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self.run_simple_test()

        # ì •ìƒì ì¸ í‰ê°€ ì§„í–‰
        for epoch in range(epochs):
            print(f"\n[*] ì—í¬í¬ {epoch + 1}/{epochs} ì„±ëŠ¥ í‰ê°€ ì¤‘...")

            # ì„±ëŠ¥ í‰ê°€
            evaluator = MemeRecommendationEvaluator(self, test_data)
            results = evaluator.evaluate_recommendations()

            # Loss ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
            epoch_loss = self.calculate_training_loss(train_data, epoch)

            # ì„±ëŠ¥ ê¸°ë¡
            self.training_history['accuracy_top1'].append(results['accuracy_top1'])
            self.training_history['accuracy_top3'].append(results['accuracy_top3'])
            self.training_history['accuracy_top5'].append(results['accuracy_top5'])
            self.training_history['loss'].append(epoch_loss)

            # ê°ì •ë³„ í‰ê·  ì •í™•ë„
            if results['emotion_accuracy']:
                emotion_avg = np.mean(list(results['emotion_accuracy'].values()))
            else:
                emotion_avg = 0.0
            self.training_history['emotion_accuracy'].append(emotion_avg)

            # ìœ ì‚¬ë„ ì ìˆ˜ í‰ê· 
            if results['detailed_results']:
                avg_similarity = np.mean([r['score'] for r in results['detailed_results']])
            else:
                avg_similarity = 0.0
            self.training_history['similarity_scores'].append(avg_similarity)

            print(f"  ì—í¬í¬ {epoch + 1} - Top-1: {results['accuracy_top1']:.3f}, Loss: {epoch_loss:.3f}")

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        evaluator.print_evaluation_report(results)

        # ì‹œê°í™” ìƒì„±
        if len(self.training_history['loss']) > 0:
            self.plot_training_curves()
            self.plot_performance_analysis(results)
            self.plot_confusion_matrix(results)

        # ê²°ê³¼ ì €ì¥
        evaluator.save_evaluation_results(results)

        return results

    def run_simple_test(self):
        """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ë°ì´í„°ê°€ ì—†ì„ ë•Œ ëŒ€ì•ˆ"""
        print("\n[*] ğŸ§ª ê°„ë‹¨í•œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")

        # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
        test_sentences = [
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„!",
            "ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
            "ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤˜ì„œ ê°ì‚¬í•´.",
            "ì‹œí—˜ì—ì„œ ë–¨ì–´ì ¸ì„œ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ.",
            "ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ê²Œ ì¬ë¯¸ìˆì–´!"
        ]

        test_results = []

        for i, sentence in enumerate(test_sentences, 1):
            print(f"\n[í…ŒìŠ¤íŠ¸ {i}/{len(test_sentences)}] {sentence}")

            try:
                result = self.recommend(sentence)
                test_results.append({
                    'input': sentence,
                    'output': result['best_image'],
                    'score': result['score'],
                    'emotions': result['emotions'],
                    'success': True
                })
                print(f"  âœ… ì¶”ì²œ: {result['best_image']} (ì ìˆ˜: {result['score']:.3f})")
                print(f"  ğŸ˜Š ê°ì •: {result['emotions']}")

            except Exception as e:
                test_results.append({
                    'input': sentence,
                    'success': False,
                    'error': str(e)
                })
                print(f"  âŒ ì‹¤íŒ¨: {e}")

        # ê°„ë‹¨í•œ í†µê³„
        success_count = sum(1 for r in test_results if r.get('success', False))
        avg_score = np.mean([r['score'] for r in test_results if r.get('success', False)])

        print(f"\nğŸ“Š ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"  ì„±ê³µë¥ : {success_count}/{len(test_sentences)} ({success_count / len(test_sentences) * 100:.1f}%)")
        if success_count > 0:
            print(f"  í‰ê·  ì ìˆ˜: {avg_score:.3f}")

        # ê°€ì§œ ê²°ê³¼ ë°˜í™˜ (ì‹œê°í™”ë¥¼ ìœ„í•´)
        return {
            'total_tests': len(test_sentences),
            'accuracy_top1': success_count / len(test_sentences),
            'accuracy_top3': success_count / len(test_sentences),
            'accuracy_top5': success_count / len(test_sentences),
            'emotion_accuracy': {},
            'situation_accuracy': {},
            'detailed_results': test_results
        }

    def calculate_training_loss(self, train_data, epoch):
        """í›ˆë ¨ loss ì‹œë®¬ë ˆì´ì…˜"""
        base_loss = 2.5
        decay_rate = 0.8
        noise = np.random.normal(0, 0.1)
        return base_loss * (decay_rate ** epoch) + noise

    # ë‚˜ë¨¸ì§€ ì‹œê°í™” ë©”ì„œë“œë“¤ì€ ë™ì¼...
    def plot_training_curves(self):
        """í›ˆë ¨ ê³¡ì„  ì‹œê°í™”"""
        if not self.training_history['loss']:
            print("[!] ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        plt.style.use('default')  # seaborn ìŠ¤íƒ€ì¼ ë¬¸ì œ ë°©ì§€
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('í›ˆë ¨ ì„±ëŠ¥ ê³¡ì„ ', fontsize=16, fontweight='bold')

        epochs = range(1, len(self.training_history['loss']) + 1)

        # 1. Loss ê³¡ì„ 
        axes[0, 0].plot(epochs, self.training_history['loss'], 'r-', linewidth=2, marker='o')
        axes[0, 0].set_title('Training Loss', fontweight='bold')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].grid(True, alpha=0.3)

        # 2. Top-K ì •í™•ë„
        axes[0, 1].plot(epochs, self.training_history['accuracy_top1'], 'b-', linewidth=2, marker='s', label='Top-1')
        axes[0, 1].plot(epochs, self.training_history['accuracy_top3'], 'g-', linewidth=2, marker='^', label='Top-3')
        axes[0, 1].plot(epochs, self.training_history['accuracy_top5'], 'orange', linewidth=2, marker='d',
                        label='Top-5')
        axes[0, 1].set_title('Top-K ì •í™•ë„', fontweight='bold')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ê°ì • ì¸ì‹ ì •í™•ë„
        axes[1, 0].plot(epochs, self.training_history['emotion_accuracy'], 'purple', linewidth=2, marker='*')
        axes[1, 0].set_title('ê°ì • ì¸ì‹ ì •í™•ë„', fontweight='bold')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Emotion Accuracy')
        axes[1, 0].grid(True, alpha=0.3)

        # 4. í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜
        axes[1, 1].plot(epochs, self.training_history['similarity_scores'], 'teal', linewidth=2, marker='h')
        axes[1, 1].set_title('í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜', fontweight='bold')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Similarity Score')
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

        plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("[*] í›ˆë ¨ ê³¡ì„ ì´ 'results/training_curves.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def plot_performance_analysis(self, results):
        """ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™”"""
        # ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ì§€ë§Œ ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ', fontsize=16, fontweight='bold')

            # 1. ê°ì •ë³„ ì •í™•ë„
            if results.get('emotion_accuracy'):
                emotions = list(results['emotion_accuracy'].keys())
                accuracies = list(results['emotion_accuracy'].values())
                if emotions:
                    bars = axes[0, 0].bar(emotions, accuracies, color=plt.cm.viridis(np.linspace(0, 1, len(emotions))))
                    axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')
                    axes[0, 0].set_ylabel('Accuracy')
                    axes[0, 0].tick_params(axis='x', rotation=45)
                else:
                    axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center')
            else:
                axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center')
            axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')

            # ë‚˜ë¨¸ì§€ ì°¨íŠ¸ë“¤ë„ ë¹„ìŠ·í•˜ê²Œ ì—ëŸ¬ í•¸ë“¤ë§...
            # (ê°„ë‹¨íˆ í•˜ê¸° ìœ„í•´ ìƒëµ)

            plt.tight_layout()
            plt.savefig('results/performance_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("[*] ì„±ëŠ¥ ë¶„ì„ì´ 'results/performance_analysis.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def plot_confusion_matrix(self, results):
        """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
        # ê¸°ì¡´ ì½”ë“œì— ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
        try:
            emotions = list(results.get('emotion_accuracy', {}).keys())
            if not emotions:
                print("[!] ê°ì • ë°ì´í„°ê°€ ì—†ì–´ í˜¼ë™ í–‰ë ¬ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼...
            print("[*] í˜¼ë™ í–‰ë ¬ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] í˜¼ë™ í–‰ë ¬ ìƒì„± ì‹¤íŒ¨: {e}")

    def save_training_history(self):
        """í›ˆë ¨ ê¸°ë¡ ì €ì¥"""
        try:
            history_file = 'results/training_history.json'
            with open(history_file, 'w', encoding='utf-8') as f:
                history_to_save = {}
                for key, values in self.training_history.items():
                    history_to_save[key] = [float(v) if isinstance(v, (np.floating, np.integer)) else v for v in values]

                json.dump(history_to_save, f, ensure_ascii=False, indent=2)
            print(f"[*] í›ˆë ¨ ê¸°ë¡ì´ '{history_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"[!] í›ˆë ¨ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”"""
    try:
        # results ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('results', exist_ok=True)

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° í‰ê°€
        system = TrainableRecommendationSystem()

        # í•™ìŠµ ë° í‰ê°€ ì‹¤í–‰
        results = system.train_and_evaluate(test_size=0.2, epochs=10)  # ì—í¬í¬ ìˆ˜ ì¤„ì„

        # í›ˆë ¨ ê¸°ë¡ ì €ì¥
        system.save_training_history()

        # ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
        print("\n" + "=" * 60)
        print("ğŸ¯ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        test_cases = [
            "ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.",
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„! ìŠ¹ì§„í–ˆì–´!",
            "ì—°ì¸ê³¼ í—¤ì–´ì ¸ì„œ ë„ˆë¬´ ìŠ¬í¼. ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´.",
            "íšŒì‚¬ ìƒì‚¬ê°€ ë„ˆë¬´ ì§œì¦ë‚˜. ê·¸ë§Œë‘ê³  ì‹¶ì–´."
        ]

        for i, dialogue in enumerate(test_cases, 1):
            print(f"\nã€ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ {i}ã€‘")
            try:
                result = system.recommend(dialogue)
                print(f"ğŸ§  ì…ë ¥: {dialogue}")
                print(f"ğŸ¯ ì¶”ì²œ: {result['best_image']}")
                print(f"ğŸ“Š ìœ ì‚¬ë„: {result['score']:.4f}")
                print(f"ğŸ˜Š ê°ì§€ ê°ì •: {result['emotions']}")
                print(f"ğŸ¢ ê°ì§€ ìƒí™©: {result['situations']}")
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("  1. data/enhanced_image_metadata.json íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        print("  2. data/images/ ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("  3. ë©”íƒ€ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ ì •ë³´ê°€ ì •í™•í•œì§€ í™•ì¸")


if __name__ == "__main__":
    main()