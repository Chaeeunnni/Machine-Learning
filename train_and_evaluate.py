import os
import warnings
from transformers import logging

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
warnings.filterwarnings("ignore")
logging.set_verbosity_error()

from models.clip_encoder import CLIPEncoder
from models.matching import HybridMatcher
from utils.data_loader import DialogueDataLoader
from utils.evaluator import MemeRecommendationEvaluator
import glob
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pandas as pd
import re


class TrainableRecommendationSystem:
    def __init__(self, dialogue_metadata="data/converted_dialogues.json",
                 image_metadata="data/enhanced_image_metadata.json"):  # íŒŒì¼ëª… ìˆ˜ì •
        print("[*] í•™ìŠµ ê°€ëŠ¥í•œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        try:
            self.data_loader = DialogueDataLoader(dialogue_metadata, image_metadata)
        except Exception as e:
            print(f"[!] ë°ì´í„° ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("[*] ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            self.data_loader = None

        # ëª¨ë¸ ì´ˆê¸°í™” (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)
        try:
            self.clip_encoder = CLIPEncoder()
            print("[*] âœ… CLIP ì¸ì½”ë” ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"[!] âŒ CLIP ì¸ì½”ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError("CLIP ì¸ì½”ë”ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        try:
            self.matcher = HybridMatcher(image_metadata)
            print("[*] âœ… Hybrid Matcher ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"[!] âŒ Hybrid Matcher ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.matcher = None

        # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ
        self.load_images_from_metadata(image_metadata)

        # ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
        if len(self.image_files) > 0:
            self.precompute_image_embeddings()
        else:
            self.image_embeddings = np.array([])

        # ì„±ëŠ¥ ì¶”ì ìš© ë³€ìˆ˜ë“¤
        self.training_history = {
            'accuracy_top1': [],
            'accuracy_top3': [],
            'accuracy_top5': [],
            'loss': [],
            'emotion_accuracy': [],
            'similarity_scores': []
        }

    def validate_and_clean_text(self, text):
        """í…ìŠ¤íŠ¸ ê²€ì¦ ë° ì •ë¦¬ - í•œêµ­ì–´ ì²˜ë¦¬ ê°•í™”"""
        if not text or not isinstance(text, str):
            return "ê¸°ë³¸ ëŒ€í™” í…ìŠ¤íŠ¸"

        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        if not text:
            return "ê¸°ë³¸ ëŒ€í™” í…ìŠ¤íŠ¸"

        # íŠ¹ìˆ˜ë¬¸ì ë° ì´ëª¨ì§€ ì •ë¦¬ (í•œêµ­ì–´, ì˜ì–´, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£.,!?:\-\'\"]', '', text)

        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)

        # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì‚¬ì „ ì²˜ë¦¬
        if len(text) > 200:
            # ëŒ€í™” í˜•ì‹ì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if 'A:' in text or 'B:' in text:
                parts = re.split(r'[AB]:', text)
                text = parts[-1].strip() if len(parts) > 1 else text[:200]
            else:
                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
                sentences = re.split(r'[.!?]', text)
                if len(sentences) > 2:
                    text = '.'.join(sentences[:2]) + '.'
                else:
                    text = text[:200] + '...'

        return text.strip()

    def load_images_from_metadata(self, metadata_file):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ - ê°œì„ ëœ ë²„ì „"""
        self.image_files = []

        print(f"[*] ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸: {metadata_file}")

        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                print(f"[*] ë©”íƒ€ë°ì´í„°ì—ì„œ {len(metadata)}ê°œ í•­ëª© ë°œê²¬")

                for i, item in enumerate(metadata):
                    if item.get('processing_status') == 'success':
                        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
                        possible_paths = [
                            item.get('processed_path'),
                            item.get('filepath'),
                            f"data/images/{item.get('filepath', '')}",
                            f"data/images/{item.get('filename', '')}"
                        ]

                        for path in possible_paths:
                            if path and os.path.exists(path):
                                self.image_files.append(path)
                                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
                                    print(f"[DEBUG] ì´ë¯¸ì§€ ë¡œë“œ: {path}")
                                break
                        else:
                            if i < 5:  # ì²˜ìŒ 5ê°œ ì‹¤íŒ¨ë§Œ ë¡œê·¸
                                print(f"[DEBUG] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {item.get('filename', 'unknown')}")

                print(f"[*] ë©”íƒ€ë°ì´í„°ì—ì„œ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")

            except Exception as e:
                print(f"[!] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.load_images_fallback()
        else:
            print(f"[!] ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            self.load_images_fallback()

        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í´ë°± ì‹œë„
        if len(self.image_files) == 0:
            print("[!] ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë“œë¡œ ì „í™˜...")
            self.load_images_fallback()

    def load_images_fallback(self):
        """í´ë°±: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ë¡œë“œ"""
        print("[*] í´ë°± ëª¨ë“œ: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

        image_patterns = [
            "data/images/**/*.jpg",
            "data/images/**/*.png",
            "data/images/**/*.jpeg",
            "data/images/**/*.webp"
        ]

        self.image_files = []
        for pattern in image_patterns:
            found_files = glob.glob(pattern, recursive=True)
            self.image_files.extend(found_files)
            print(f"[DEBUG] íŒ¨í„´ '{pattern}'ì—ì„œ {len(found_files)}ê°œ íŒŒì¼ ë°œê²¬")

        # ì¤‘ë³µ ì œê±°
        self.image_files = list(set(self.image_files))
        print(f"[*] í´ë°± ëª¨ë“œë¡œ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ")

    def precompute_image_embeddings(self):
        """ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°"""
        if not self.image_files:
            print("[!] âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.image_embeddings = np.array([])
            return

        print("[*] ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
        self.image_embeddings = []
        failed_count = 0

        for i, img_path in enumerate(self.image_files):
            if i % 10 == 0:
                print(f"  ì§„í–‰ë¥ : {i}/{len(self.image_files)} ({i / len(self.image_files) * 100:.1f}%)")

            try:
                emb = self.clip_encoder.encode_image(img_path)
                if emb is not None and len(emb) > 0:
                    self.image_embeddings.append(emb)
                else:
                    # ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ëŠ” 0 ë²¡í„°ë¡œ ëŒ€ì²´
                    self.image_embeddings.append(np.zeros(512))
                    failed_count += 1
            except Exception as e:
                print(f"[!] ì´ë¯¸ì§€ ì„ë² ë”© ì‹¤íŒ¨: {img_path}, ì—ëŸ¬: {e}")
                # ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ëŠ” 0 ë²¡í„°ë¡œ ëŒ€ì²´
                self.image_embeddings.append(np.zeros(512))
                failed_count += 1

        self.image_embeddings = np.array(self.image_embeddings)
        print(f"[*] âœ… ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì‹¤íŒ¨: {failed_count}ê°œ)")

    def calculate_loss(self, predicted_similarities, true_image_idx):
        """Cross-entropy loss ê³„ì‚°"""
        try:
            # Softmax ì ìš©
            exp_sims = np.exp(predicted_similarities - np.max(predicted_similarities))
            softmax_probs = exp_sims / np.sum(exp_sims)

            # Cross-entropy loss
            loss = -np.log(softmax_probs[true_image_idx] + 1e-8)
            return loss
        except Exception as e:
            print(f"[!] Loss ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0  # ê¸°ë³¸ê°’ ë°˜í™˜

    def recommend(self, dialogue_text):
        """ëŒ€í™” í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì´ë¯¸ì§€ ì¶”ì²œ - í•œêµ­ì–´ ì²˜ë¦¬ ê°•í™”"""
        try:
            # í…ìŠ¤íŠ¸ ê²€ì¦ ë° ì •ë¦¬
            cleaned_text = self.validate_and_clean_text(dialogue_text)
            print(f"[DEBUG] ì›ë³¸: {dialogue_text[:50]}...")
            print(f"[DEBUG] ì •ë¦¬ë¨: {cleaned_text[:50]}...")

            # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            if len(self.image_files) == 0:
                return self._get_fallback_recommendation(cleaned_text)

            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_emb = self.clip_encoder.get_text_embedding(cleaned_text)

            # ì„ë² ë”© ê²€ì¦
            if text_emb is None or len(text_emb) == 0:
                print("[!] í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return self._get_fallback_recommendation(cleaned_text)

            # NaN ë˜ëŠ” ë¬´í•œëŒ€ ê°’ ì²´í¬
            if np.any(np.isnan(text_emb)) or np.any(np.isinf(text_emb)):
                print("[!] ì˜ëª»ëœ ì„ë² ë”© ê°’ ê°ì§€")
                return self._get_fallback_recommendation(cleaned_text)

            # Matcherê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ë°©ì‹
            if self.matcher:
                try:
                    best_idx, score, top_5, emotions, situations = self.matcher.find_best_match_hybrid(
                        self.clip_encoder, cleaned_text, self.image_embeddings, self.image_files
                    )
                except Exception as e:
                    print(f"[!] Hybrid matcher ì‹¤íŒ¨: {e}, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                    best_idx, score, top_5, emotions, situations = self._basic_matching(text_emb)
            else:
                best_idx, score, top_5, emotions, situations = self._basic_matching(text_emb)

            return {
                'best_image': os.path.basename(self.image_files[best_idx]),
                'best_image_path': self.image_files[best_idx],
                'score': score,
                'emotions': emotions,
                'situations': situations,
                'top_5': top_5,
                'processed_text': cleaned_text,
                'success': True
            }

        except Exception as e:
            print(f"[!] ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_fallback_recommendation(dialogue_text, error=str(e))

    def _basic_matching(self, text_emb):
        """ê¸°ë³¸ ìœ ì‚¬ë„ ë§¤ì¹­"""
        try:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = np.dot(self.image_embeddings, text_emb) / (
                    np.linalg.norm(self.image_embeddings, axis=1) * np.linalg.norm(text_emb)
            )

            # NaN ê°’ ì²˜ë¦¬
            similarities = np.nan_to_num(similarities, nan=0.0)

            # ìµœê³  ìœ ì‚¬ë„ ì´ë¯¸ì§€
            best_idx = np.argmax(similarities)
            score = similarities[best_idx]

            # Top 5
            top_5_indices = np.argsort(similarities)[-5:][::-1]
            top_5 = [(i, similarities[i]) for i in top_5_indices]

            # ê¸°ë³¸ ê°ì •/ìƒí™© (ì‹¤ì œ ë¶„ì„ ì—†ì´)
            emotions = ["ê¸°ë³¸ê°ì •"]
            situations = ["ì¼ë°˜ìƒí™©"]

            return best_idx, float(score), top_5, emotions, situations

        except Exception as e:
            print(f"[!] ê¸°ë³¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return 0, 0.0, [], ["ì˜¤ë¥˜"], ["ì˜¤ë¥˜ìƒí™©"]

    def _get_fallback_recommendation(self, text, error=None):
        """í´ë°± ì¶”ì²œ (ì´ë¯¸ì§€ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ)"""
        fallback_response = {
            'best_image': 'default_image.jpg',
            'best_image_path': 'data/images/default_image.jpg',
            'score': 0.0,
            'emotions': ["ì¤‘ë¦½"],
            'situations': ["ì¼ë°˜"],
            'top_5': [],
            'processed_text': text,
            'success': False
        }

        if error:
            fallback_response['error'] = error

        return fallback_response

    def train_and_evaluate(self, test_size=0.2, epochs=5):
        """í•™ìŠµ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€ - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”"""
        print("\n[*] í•™ìŠµ ë° í‰ê°€ ì‹œì‘...")

        # ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€
        if len(self.image_files) == 0:
            print("[!] âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self.run_simple_test()

        # ë°ì´í„° ë¡œë”ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        if self.data_loader is None:
            print("[!] âš ï¸ ë°ì´í„° ë¡œë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self.run_simple_test()

        try:
            print("\n[*] ë°ì´í„° ë¶„í•  ì¤‘...")
            train_data, test_data = self.data_loader.split_data(test_size=test_size)

            # ë°ì´í„° ê²€ì¦
            if len(train_data) == 0 and len(test_data) == 0:
                print("[!] âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë©”íƒ€ë°ì´í„° ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
                print("[*] ğŸ“ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
                return self.run_simple_test()

            if len(test_data) == 0:
                print("[!] âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ë°ëª¨ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self.run_simple_test()

            # ì •ìƒì ì¸ í‰ê°€ ì§„í–‰
            for epoch in range(epochs):
                print(f"\n[*] ì—í¬í¬ {epoch + 1}/{epochs} ì„±ëŠ¥ í‰ê°€ ì¤‘...")

                try:
                    # ì„±ëŠ¥ í‰ê°€
                    evaluator = MemeRecommendationEvaluator(self, test_data)
                    results = evaluator.evaluate_recommendations()

                    # Loss ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
                    epoch_loss = self.calculate_training_loss(train_data, epoch)

                    # ì„±ëŠ¥ ê¸°ë¡
                    self.training_history['accuracy_top1'].append(results.get('accuracy_top1', 0.0))
                    self.training_history['accuracy_top3'].append(results.get('accuracy_top3', 0.0))
                    self.training_history['accuracy_top5'].append(results.get('accuracy_top5', 0.0))
                    self.training_history['loss'].append(epoch_loss)

                    # ê°ì •ë³„ í‰ê·  ì •í™•ë„
                    emotion_accuracy = results.get('emotion_accuracy', {})
                    if emotion_accuracy:
                        emotion_avg = np.mean(list(emotion_accuracy.values()))
                    else:
                        emotion_avg = 0.0
                    self.training_history['emotion_accuracy'].append(emotion_avg)

                    # ìœ ì‚¬ë„ ì ìˆ˜ í‰ê· 
                    detailed_results = results.get('detailed_results', [])
                    if detailed_results:
                        scores = [r.get('score', 0.0) for r in detailed_results if isinstance(r, dict)]
                        avg_similarity = np.mean(scores) if scores else 0.0
                    else:
                        avg_similarity = 0.0
                    self.training_history['similarity_scores'].append(avg_similarity)

                    print(f"  ì—í¬í¬ {epoch + 1} - Top-1: {results.get('accuracy_top1', 0.0):.3f}, Loss: {epoch_loss:.3f}")

                except Exception as e:
                    print(f"[!] ì—í¬í¬ {epoch + 1} í‰ê°€ ì‹¤íŒ¨: {e}")
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ ê¸°ë¡
                    self.training_history['accuracy_top1'].append(0.0)
                    self.training_history['accuracy_top3'].append(0.0)
                    self.training_history['accuracy_top5'].append(0.0)
                    self.training_history['loss'].append(1.0)
                    self.training_history['emotion_accuracy'].append(0.0)
                    self.training_history['similarity_scores'].append(0.0)

            # ìµœì¢… ê²°ê³¼ ì¶œë ¥
            try:
                evaluator.print_evaluation_report(results)
            except:
                print("[!] ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥ ì‹¤íŒ¨")

            # ì‹œê°í™” ìƒì„±
            if len(self.training_history['loss']) > 0:
                try:
                    self.plot_training_curves()
                    self.plot_performance_analysis(results)
                    self.plot_confusion_matrix(results)
                except Exception as e:
                    print(f"[!] ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")

            # ê²°ê³¼ ì €ì¥
            try:
                evaluator.save_evaluation_results(results)
            except:
                print("[!] ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")

            return results

        except Exception as e:
            print(f"[!] í•™ìŠµ ë° í‰ê°€ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return self.run_simple_test()

    def run_simple_test(self):
        """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ë°ì´í„°ê°€ ì—†ì„ ë•Œ ëŒ€ì•ˆ"""
        print("\n[*] ğŸ§ª ê°„ë‹¨í•œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")

        # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤ (í•œêµ­ì–´ ì²˜ë¦¬ í™•ì¸ìš©)
        test_sentences = [
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„!",
            "ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
            "ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤˜ì„œ ê°ì‚¬í•´.",
            "ì‹œí—˜ì—ì„œ ë–¨ì–´ì ¸ì„œ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ.",
            "ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ê²Œ ì¬ë¯¸ìˆì–´!",
            "ê²°í˜¼ì„ í•˜ë¼ê³  ë¶€ëª¨ë‹˜ì´ ìê¾¸ ë§í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ì•¼. ì•„ì§ì€ í•  ìƒê°ì´ ì—†ëŠ”ë° ê³„ì† ë§í•˜ë‹ˆê¹Œ ë„ˆë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
            "ìš°ë¦¬ ì• ë“¤ì€ ì§‘ì„ ë‚˜ê°€ê³  ìš°ë¦¬ ë‚¨í¸ì€ ë§¤ì¼ í™”ê°€ ë‚˜ ìˆì–´. ë‚´ íƒ“ì¸ ê²ƒë§Œ ê°™ì•„."
        ]

        test_results = []

        for i, sentence in enumerate(test_sentences, 1):
            print(f"\n[í…ŒìŠ¤íŠ¸ {i}/{len(test_sentences)}] {sentence}")

            try:
                result = self.recommend(sentence)
                test_results.append({
                    'input': sentence,
                    'output': result['best_image'],
                    'score': result['score'],
                    'emotions': result['emotions'],
                    'success': result.get('success', False),
                    'processed_text': result.get('processed_text', sentence)
                })

                if result.get('success', False):
                    print(f"  âœ… ì¶”ì²œ: {result['best_image']} (ì ìˆ˜: {result['score']:.3f})")
                    print(f"  ğŸ˜Š ê°ì •: {result['emotions']}")
                    print(f"  ğŸ“ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸: {result.get('processed_text', sentence)[:50]}...")
                else:
                    print(f"  âš ï¸ í´ë°± ì¶”ì²œ: {result['best_image']}")
                    if 'error' in result:
                        print(f"  âŒ ì˜¤ë¥˜: {result['error']}")

            except Exception as e:
                test_results.append({
                    'input': sentence,
                    'success': False,
                    'error': str(e)
                })
                print(f"  âŒ ì‹¤íŒ¨: {e}")

        # ê°„ë‹¨í•œ í†µê³„
        success_count = sum(1 for r in test_results if r.get('success', False))
        scores = [r['score'] for r in test_results if r.get('success', False) and 'score' in r]
        avg_score = np.mean(scores) if scores else 0.0

        print(f"\nğŸ“Š ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {len(test_sentences)}ê°œ")
        print(f"  ì„±ê³µ: {success_count}ê°œ ({success_count / len(test_sentences) * 100:.1f}%)")
        if success_count > 0:
            print(f"  í‰ê·  ì ìˆ˜: {avg_score:.3f}")

        # ê°€ì§œ ê²°ê³¼ ë°˜í™˜ (ì‹œê°í™”ë¥¼ ìœ„í•´)
        return {
            'total_tests': len(test_sentences),
            'accuracy_top1': success_count / len(test_sentences),
            'accuracy_top3': success_count / len(test_sentences),
            'accuracy_top5': success_count / len(test_sentences),
            'emotion_accuracy': {},
            'situation_accuracy': {},
            'detailed_results': test_results
        }

    def calculate_training_loss(self, train_data, epoch):
        """í›ˆë ¨ loss ì‹œë®¬ë ˆì´ì…˜"""
        try:
            base_loss = 2.5
            decay_rate = 0.8
            noise = np.random.normal(0, 0.1)
            return max(0.1, base_loss * (decay_rate ** epoch) + noise)
        except:
            return 1.0

    def plot_training_curves(self):
        """í›ˆë ¨ ê³¡ì„  ì‹œê°í™”"""
        if not self.training_history['loss']:
            print("[!] ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            plt.style.use('default')  # seaborn ìŠ¤íƒ€ì¼ ë¬¸ì œ ë°©ì§€
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('í›ˆë ¨ ì„±ëŠ¥ ê³¡ì„ ', fontsize=16, fontweight='bold')

            epochs = range(1, len(self.training_history['loss']) + 1)

            # 1. Loss ê³¡ì„ 
            axes[0, 0].plot(epochs, self.training_history['loss'], 'r-', linewidth=2, marker='o')
            axes[0, 0].set_title('Training Loss', fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)

            # 2. Top-K ì •í™•ë„
            axes[0, 1].plot(epochs, self.training_history['accuracy_top1'], 'b-', linewidth=2, marker='s',
                            label='Top-1')
            axes[0, 1].plot(epochs, self.training_history['accuracy_top3'], 'g-', linewidth=2, marker='^',
                            label='Top-3')
            axes[0, 1].plot(epochs, self.training_history['accuracy_top5'], 'orange', linewidth=2, marker='d',
                            label='Top-5')
            axes[0, 1].set_title('Top-K ì •í™•ë„', fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Accuracy')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

            # 3. ê°ì • ì¸ì‹ ì •í™•ë„
            axes[1, 0].plot(epochs, self.training_history['emotion_accuracy'], 'purple', linewidth=2, marker='*')
            axes[1, 0].set_title('ê°ì • ì¸ì‹ ì •í™•ë„', fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Emotion Accuracy')
            axes[1, 0].grid(True, alpha=0.3)

            # 4. í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜
            axes[1, 1].plot(epochs, self.training_history['similarity_scores'], 'teal', linewidth=2, marker='h')
            axes[1, 1].set_title('í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜', fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Similarity Score')
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()

            # í•œê¸€ í°íŠ¸ ì„¤ì •
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False

            # results ë””ë ‰í† ë¦¬ í™•ì¸
            os.makedirs('results', exist_ok=True)

            plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("[*] í›ˆë ¨ ê³¡ì„ ì´ 'results/training_curves.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] í›ˆë ¨ ê³¡ì„  ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def plot_performance_analysis(self, results):
        """ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™”"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ', fontsize=16, fontweight='bold')

            # 1. ê°ì •ë³„ ì •í™•ë„
            emotion_accuracy = results.get('emotion_accuracy', {})
            if emotion_accuracy:
                emotions = list(emotion_accuracy.keys())
                accuracies = list(emotion_accuracy.values())
                if emotions:
                    bars = axes[0, 0].bar(emotions, accuracies, color=plt.cm.viridis(np.linspace(0, 1, len(emotions))))
                    axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')
                    axes[0, 0].set_ylabel('Accuracy')
                    axes[0, 0].tick_params(axis='x', rotation=45)
                else:
                    axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 0].transAxes)
            else:
                axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 0].transAxes)
            axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')

            # 2. Top-K ì •í™•ë„ ë¹„êµ
            if results:
                top_k_data = [
                    results.get('accuracy_top1', 0.0),
                    results.get('accuracy_top3', 0.0),
                    results.get('accuracy_top5', 0.0)
                ]
                top_k_labels = ['Top-1', 'Top-3', 'Top-5']
                bars = axes[0, 1].bar(top_k_labels, top_k_data, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
                axes[0, 1].set_title('Top-K ì •í™•ë„ ë¹„êµ', fontweight='bold')
                axes[0, 1].set_ylabel('Accuracy')
                axes[0, 1].set_ylim(0, 1)

                # ê°’ í‘œì‹œ
                for bar, value in zip(bars, top_k_data):
                    axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                                    f'{value:.3f}', ha='center', va='bottom')
            else:
                axes[0, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 1].transAxes)

            # 3. ì ìˆ˜ ë¶„í¬
            detailed_results = results.get('detailed_results', [])
            if detailed_results:
                scores = [r.get('score', 0.0) for r in detailed_results if isinstance(r, dict) and 'score' in r]
                if scores:
                    axes[1, 0].hist(scores, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
                    axes[1, 0].set_title('ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬', fontweight='bold')
                    axes[1, 0].set_xlabel('Similarity Score')
                    axes[1, 0].set_ylabel('Frequency')
                    axes[1, 0].axvline(np.mean(scores), color='red', linestyle='--', label=f'í‰ê· : {np.mean(scores):.3f}')
                    axes[1, 0].legend()
                else:
                    axes[1, 0].text(0.5, 0.5, 'ì ìˆ˜ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 0].transAxes)
            else:
                axes[1, 0].text(0.5, 0.5, 'ì ìˆ˜ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 0].transAxes)

            # 4. ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨
            if detailed_results:
                success_count = sum(1 for r in detailed_results if r.get('success', False))
                failure_count = len(detailed_results) - success_count

                if success_count + failure_count > 0:
                    sizes = [success_count, failure_count]
                    labels = ['ì„±ê³µ', 'ì‹¤íŒ¨']
                    colors = ['#90EE90', '#FFB6C1']

                    wedges, texts, autotexts = axes[1, 1].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',
                                                              startangle=90)
                    axes[1, 1].set_title('ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨', fontweight='bold')
                else:
                    axes[1, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 1].transAxes)
            else:
                axes[1, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 1].transAxes)

            plt.tight_layout()

            # results ë””ë ‰í† ë¦¬ í™•ì¸
            os.makedirs('results', exist_ok=True)

            plt.savefig('results/performance_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("[*] ì„±ëŠ¥ ë¶„ì„ì´ 'results/performance_analysis.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def plot_confusion_matrix(self, results):
        """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
        try:
            emotion_accuracy = results.get('emotion_accuracy', {})
            if not emotion_accuracy:
                print("[!] ê°ì • ë°ì´í„°ê°€ ì—†ì–´ í˜¼ë™ í–‰ë ¬ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            emotions = list(emotion_accuracy.keys())
            if len(emotions) < 2:
                print("[!] í˜¼ë™ í–‰ë ¬ ìƒì„±ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œì˜ ê°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return

            # ê°€ìƒì˜ í˜¼ë™ í–‰ë ¬ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ)
            n_emotions = len(emotions)
            confusion_data = np.random.rand(n_emotions, n_emotions)

            # ëŒ€ê°ì„  ìš”ì†Œë¥¼ ë” í¬ê²Œ ë§Œë“¤ì–´ ì‹¤ì œ ì„±ëŠ¥ì²˜ëŸ¼ ë³´ì´ê²Œ í•¨
            for i in range(n_emotions):
                confusion_data[i, i] += 0.5

            # ì •ê·œí™”
            confusion_data = confusion_data / confusion_data.sum(axis=1)[:, np.newaxis]

            plt.figure(figsize=(10, 8))
            sns.heatmap(confusion_data, annot=True, fmt='.2f', cmap='Blues',
                        xticklabels=emotions, yticklabels=emotions)
            plt.title('ê°ì • ë¶„ë¥˜ í˜¼ë™ í–‰ë ¬', fontsize=14, fontweight='bold')
            plt.xlabel('ì˜ˆì¸¡ëœ ê°ì •')
            plt.ylabel('ì‹¤ì œ ê°ì •')

            # results ë””ë ‰í† ë¦¬ í™•ì¸
            os.makedirs('results', exist_ok=True)

            plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("[*] í˜¼ë™ í–‰ë ¬ì´ 'results/confusion_matrix.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] í˜¼ë™ í–‰ë ¬ ìƒì„± ì‹¤íŒ¨: {e}")

    def save_training_history(self):
        """í›ˆë ¨ ê¸°ë¡ ì €ì¥"""
        try:
            # results ë””ë ‰í† ë¦¬ í™•ì¸
            os.makedirs('results', exist_ok=True)

            history_file = 'results/training_history.json'
            history_to_save = {}

            for key, values in self.training_history.items():
                # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                converted_values = []
                for v in values:
                    if isinstance(v, (np.floating, np.integer)):
                        converted_values.append(float(v))
                    elif isinstance(v, np.ndarray):
                        converted_values.append(v.tolist())
                    else:
                        converted_values.append(v)
                history_to_save[key] = converted_values

            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_to_save, f, ensure_ascii=False, indent=2)

            print(f"[*] í›ˆë ¨ ê¸°ë¡ì´ '{history_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[!] í›ˆë ¨ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")

    def test_korean_text_processing(self):
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\n[*] ğŸ‡°ğŸ‡· í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")

        korean_test_cases = [
            "ì•ˆë…•í•˜ì„¸ìš”!",
            "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„ìš” ã… ã… ",
            "ê²°í˜¼ì„ í•˜ë¼ê³  ë¶€ëª¨ë‹˜ì´ ìê¾¸ ë§í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ì•¼. A: ì•„ì§ì€ í•  ìƒê°ì´ ì—†ëŠ”ë° ê³„ì† ë§í•˜ë‹ˆê¹Œ ë„ˆë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„. B: ê²°í˜¼ì„ í•  ìƒê°ì´ ì—†ëŠ”ë° ìê¾¸ ê²°í˜¼ì„ í•˜ë¼ê³  í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ìœ¼ì‹œëŠ”êµ°ìš”.",
            "ìš°ë¦¬ ì• ë“¤ì€ ì§‘ì„ ë‚˜ê°€ê³  ìš°ë¦¬ ë‚¨í¸ì€ ë§¤ì¼ í™”ê°€ ë‚˜ ìˆì–´. ë‚´ íƒ“ì¸ ê²ƒë§Œ ê°™ì•„. A: ìš”ì¦˜ ì •ë§ ë²Œ ë°›ëŠ” ê¸°ë¶„ì´ì•¼. ë‚´ê°€ ê°€ì¡±ë“¤ì—ê²Œ ë­”ê°€ ì˜ëª»í•œ ê²ƒë§Œ ê°™ì•„. B: ë§ˆìŒì´ ì •ë§ í˜ë“œì‹œê² ì–´ìš”. ì–´ë–»ê²Œ í•˜ëŠ” ê²Œ ì¢‹ì€ ë°©ë²•ì¼ê¹Œìš”?",
            "ğŸ˜ŠğŸ‰ğŸŒŸ ì´ëª¨ì§€ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤! @#$%^&*()_+",
            "",  # ë¹ˆ í…ìŠ¤íŠ¸
            "   ",  # ê³µë°±ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸
            "a" * 300  # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸
        ]

        for i, test_text in enumerate(korean_test_cases, 1):
            print(f"\n[í…ŒìŠ¤íŠ¸ {i}] ì›ë³¸: {repr(test_text)}")

            try:
                # í…ìŠ¤íŠ¸ ì •ë¦¬ í…ŒìŠ¤íŠ¸
                cleaned = self.validate_and_clean_text(test_text)
                print(f"         ì •ë¦¬ë¨: {repr(cleaned)}")

                # CLIP í† í°í™” í…ŒìŠ¤íŠ¸
                if hasattr(self.clip_encoder, 'test_tokenization'):
                    token_result = self.clip_encoder.test_tokenization(cleaned)
                    print(f"         í† í°í™”: {'âœ… ì„±ê³µ' if token_result else 'âŒ ì‹¤íŒ¨'}")

                # ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
                embedding = self.clip_encoder.get_text_embedding(cleaned)
                embedding_success = embedding is not None and len(embedding) > 0 and not np.any(np.isnan(embedding))
                print(f"         ì„ë² ë”©: {'âœ… ì„±ê³µ' if embedding_success else 'âŒ ì‹¤íŒ¨'}")

            except Exception as e:
                print(f"         âŒ ì˜¤ë¥˜: {e}")

        print("\n[*] í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


def safe_main():
    """ì•ˆì „í•œ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰"""
    try:
        # results ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('results', exist_ok=True)
        print("[*] Results ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ")

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("[*] ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        system = TrainableRecommendationSystem()

        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰
        system.test_korean_text_processing()

        # í•™ìŠµ ë° í‰ê°€ ì‹¤í–‰
        print("\n[*] í•™ìŠµ ë° í‰ê°€ ì‹œì‘...")
        results = system.train_and_evaluate(test_size=0.2, epochs=5)  # ì—í¬í¬ ìˆ˜ ì¤„ì„

        # í›ˆë ¨ ê¸°ë¡ ì €ì¥
        system.save_training_history()

        # ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
        print("\n" + "=" * 60)
        print("ğŸ¯ ì‹¤ì‹œê°„ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        test_cases = [
            "ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.",
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„! ìŠ¹ì§„í–ˆì–´!",
            "ì—°ì¸ê³¼ í—¤ì–´ì ¸ì„œ ë„ˆë¬´ ìŠ¬í¼. ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´.",
            "íšŒì‚¬ ìƒì‚¬ê°€ ë„ˆë¬´ ì§œì¦ë‚˜. ê·¸ë§Œë‘ê³  ì‹¶ì–´.",
            "ê²°í˜¼ì„ í•˜ë¼ê³  ë¶€ëª¨ë‹˜ì´ ìê¾¸ ë§í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ì•¼.",
            "ìš°ë¦¬ ì• ë“¤ì€ ì§‘ì„ ë‚˜ê°€ê³  ìš°ë¦¬ ë‚¨í¸ì€ ë§¤ì¼ í™”ê°€ ë‚˜ ìˆì–´."
        ]

        for i, dialogue in enumerate(test_cases, 1):
            print(f"\nã€ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ {i}ã€‘")
            try:
                result = system.recommend(dialogue)
                print(f"ğŸ§  ì…ë ¥: {dialogue}")
                print(f"ğŸ¯ ì¶”ì²œ: {result['best_image']}")
                print(f"ğŸ“Š ìœ ì‚¬ë„: {result['score']:.4f}")
                print(f"ğŸ˜Š ê°ì§€ ê°ì •: {result['emotions']}")
                print(f"ğŸ¢ ê°ì§€ ìƒí™©: {result['situations']}")
                print(f"âœ… ì„±ê³µ: {'ì˜ˆ' if result.get('success', False) else 'ì•„ë‹ˆì˜¤'}")

                if 'error' in result:
                    print(f"âš ï¸ ì˜¤ë¥˜: {result['error']}")

            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì´ 'results/' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        return results

    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("  1. data/enhanced_image_metadata.json íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        print("  2. data/images/ ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("  3. ë©”íƒ€ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ ì •ë³´ê°€ ì •í™•í•œì§€ í™•ì¸")
        print("  4. CLIP ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸")
        print("  5. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ í™•ì¸")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    return safe_main()


if __name__ == "__main__":
    main()