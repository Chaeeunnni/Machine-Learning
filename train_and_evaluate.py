# train_and_evaluate.py - ì™„ì „ ìˆ˜ì •ëœ ë²„ì „

import os
import warnings
from transformers import logging

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
warnings.filterwarnings("ignore")
logging.set_verbosity_error()

# ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
DEBUG_MODE = False
SHOW_DIALOGUE_CONTENT = False
SHOW_EMOTION_ANALYSIS = False


def debug_print(*args, **kwargs):
    """ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥"""
    if DEBUG_MODE:
        print("[DEBUG]", *args, **kwargs)


def info_print(*args, **kwargs):
    """ì¼ë°˜ ì •ë³´ ì¶œë ¥"""
    print("[*]", *args, **kwargs)


def progress_print(*args, **kwargs):
    """ì§„í–‰ë¥  ì¶œë ¥"""
    print("  ", *args, **kwargs)


def error_print(*args, **kwargs):
    """ì˜¤ë¥˜ ì¶œë ¥"""
    print("[!]", *args, **kwargs)


# ëª¨ë“ˆ import (ì ˆëŒ€ import ì‚¬ìš©)
try:
    from models.clip_encoder import CLIPEncoder

    info_print("CLIPEncoder import ì„±ê³µ")
except ImportError as e:
    error_print(f"CLIPEncoder import ì‹¤íŒ¨: {e}")
    raise

try:
    from models.matching import HybridMatcher

    info_print("HybridMatcher import ì„±ê³µ")
except ImportError as e:
    error_print(f"HybridMatcher import ì‹¤íŒ¨: {e}")
    # HybridMatcher ì—†ì´ë„ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡
    HybridMatcher = None

try:
    from utils.data_loader import DialogueDataLoader

    info_print("DialogueDataLoader import ì„±ê³µ")
except ImportError as e:
    error_print(f"DialogueDataLoader import ì‹¤íŒ¨: {e}")
    DialogueDataLoader = None

try:
    from utils.evaluator import MemeRecommendationEvaluator

    info_print("MemeRecommendationEvaluator import ì„±ê³µ")
except ImportError as e:
    error_print(f"MemeRecommendationEvaluator import ì‹¤íŒ¨: {e}")
    MemeRecommendationEvaluator = None

import glob
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pandas as pd
import re


class TrainableRecommendationSystem:
    def __init__(self, dialogue_metadata="data/converted_dialogues.json",
                 image_metadata="data/enhanced_image_metadata.json"):
        info_print("í•™ìŠµ ê°€ëŠ¥í•œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        self.data_loader = None
        if DialogueDataLoader:
            try:
                self.data_loader = DialogueDataLoader(dialogue_metadata, image_metadata)
                info_print("âœ… ë°ì´í„° ë¡œë” ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                error_print(f"ë°ì´í„° ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # ëª¨ë¸ ì´ˆê¸°í™”
        try:
            self.clip_encoder = CLIPEncoder()
            info_print("âœ… CLIP ì¸ì½”ë” ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            error_print(f"âŒ CLIP ì¸ì½”ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError("CLIP ì¸ì½”ë”ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # Matcher ì´ˆê¸°í™”
        self.matcher = None
        if HybridMatcher:
            try:
                self.matcher = HybridMatcher(image_metadata)
                info_print("âœ… Hybrid Matcher ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                error_print(f"Hybrid Matcher ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ
        self.load_images_from_metadata(image_metadata)

        # ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
        if len(self.image_files) > 0:
            self.precompute_image_embeddings()
        else:
            self.image_embeddings = np.array([])

        # ì„±ëŠ¥ ì¶”ì ìš© ë³€ìˆ˜ë“¤
        self.training_history = {
            'accuracy_top1': [],
            'accuracy_top3': [],
            'accuracy_top5': [],
            'loss': [],
            'emotion_accuracy': [],
            'similarity_scores': []
        }

    def validate_and_clean_text(self, text):
        """í…ìŠ¤íŠ¸ ê²€ì¦ ë° ì •ë¦¬"""
        if not text or not isinstance(text, str):
            return "ê¸°ë³¸ ëŒ€í™” í…ìŠ¤íŠ¸"

        text = text.strip()
        if not text:
            return "ê¸°ë³¸ ëŒ€í™” í…ìŠ¤íŠ¸"

        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        text = re.sub(r'[^\w\sê°€-í£.,!?:\-\'\"]', '', text)
        text = re.sub(r'\s+', ' ', text)

        # ê¸¸ì´ ì œí•œ
        if len(text) > 200:
            if 'A:' in text or 'B:' in text:
                parts = re.split(r'[AB]:', text)
                text = parts[-1].strip() if len(parts) > 1 else text[:200]
            else:
                sentences = re.split(r'[.!?]', text)
                if len(sentences) > 2:
                    text = '.'.join(sentences[:2]) + '.'
                else:
                    text = text[:200] + '...'

        return text.strip()

    def load_images_from_metadata(self, metadata_file):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ"""
        self.image_files = []

        info_print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸: {metadata_file}")

        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                info_print(f"ë©”íƒ€ë°ì´í„°ì—ì„œ {len(metadata)}ê°œ í•­ëª© ë°œê²¬")

                for i, item in enumerate(metadata):
                    if item.get('processing_status') == 'success':
                        possible_paths = [
                            item.get('processed_path'),
                            item.get('filepath'),
                            f"data/images/{item.get('filepath', '')}",
                            f"data/images/{item.get('filename', '')}"
                        ]

                        for path in possible_paths:
                            if path and os.path.exists(path):
                                self.image_files.append(path)
                                break

                info_print(f"ë©”íƒ€ë°ì´í„°ì—ì„œ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")

            except Exception as e:
                error_print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.load_images_fallback()
        else:
            error_print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            self.load_images_fallback()

        if len(self.image_files) == 0:
            error_print("ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë“œë¡œ ì „í™˜...")
            self.load_images_fallback()

    def load_images_fallback(self):
        """í´ë°±: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ë¡œë“œ"""
        info_print("í´ë°± ëª¨ë“œ: ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

        image_patterns = [
            "data/images/**/*.jpg",
            "data/images/**/*.png",
            "data/images/**/*.jpeg",
            "data/images/**/*.webp"
        ]

        self.image_files = []
        for pattern in image_patterns:
            found_files = glob.glob(pattern, recursive=True)
            self.image_files.extend(found_files)

        self.image_files = list(set(self.image_files))
        info_print(f"í´ë°± ëª¨ë“œë¡œ ì´ {len(self.image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ")

    def precompute_image_embeddings(self):
        """ì´ë¯¸ì§€ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°"""
        if not self.image_files:
            error_print("âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.image_embeddings = np.array([])
            return

        info_print("ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
        self.image_embeddings = []
        failed_count = 0

        for i, img_path in enumerate(self.image_files):
            if i % 10 == 0:
                progress_print(f"ì§„í–‰ë¥ : {i}/{len(self.image_files)} ({i / len(self.image_files) * 100:.1f}%)")

            try:
                emb = self.clip_encoder.encode_image(img_path)
                if emb is not None and len(emb) > 0:
                    self.image_embeddings.append(emb)
                else:
                    self.image_embeddings.append(np.zeros(512))
                    failed_count += 1
            except Exception as e:
                debug_print(f"ì´ë¯¸ì§€ ì„ë² ë”© ì‹¤íŒ¨: {img_path}, ì—ëŸ¬: {e}")
                self.image_embeddings.append(np.zeros(512))
                failed_count += 1

        self.image_embeddings = np.array(self.image_embeddings)
        info_print(f"âœ… ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì‹¤íŒ¨: {failed_count}ê°œ)")

    def recommend(self, dialogue_text):
        """ëŒ€í™” í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì´ë¯¸ì§€ ì¶”ì²œ"""
        try:
            cleaned_text = self.validate_and_clean_text(dialogue_text)

            if SHOW_DIALOGUE_CONTENT:
                debug_print(f"ì›ë³¸: {dialogue_text[:50]}...")
                debug_print(f"ì •ë¦¬ë¨: {cleaned_text[:50]}...")

            if len(self.image_files) == 0:
                return self._get_fallback_recommendation(cleaned_text)

            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_emb = self.clip_encoder.get_text_embedding(cleaned_text)

            if text_emb is None or len(text_emb) == 0:
                debug_print("í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return self._get_fallback_recommendation(cleaned_text)

            if np.any(np.isnan(text_emb)) or np.any(np.isinf(text_emb)):
                debug_print("ì˜ëª»ëœ ì„ë² ë”© ê°’ ê°ì§€")
                return self._get_fallback_recommendation(cleaned_text)

            # Matcher ì‚¬ìš©
            if self.matcher:
                try:
                    best_idx, score, top_5, emotions, situations = self.matcher.find_best_match_hybrid(
                        self.clip_encoder, cleaned_text, self.image_embeddings, self.image_files
                    )
                except Exception as e:
                    debug_print(f"Hybrid matcher ì‹¤íŒ¨: {e}, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                    best_idx, score, top_5, emotions, situations = self._basic_matching(text_emb)
            else:
                best_idx, score, top_5, emotions, situations = self._basic_matching(text_emb)

            return {
                'best_image': os.path.basename(self.image_files[best_idx]),
                'best_image_path': self.image_files[best_idx],
                'score': score,
                'emotions': emotions,
                'situations': situations,
                'top_5': top_5,
                'processed_text': cleaned_text,
                'success': True
            }

        except Exception as e:
            debug_print(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_fallback_recommendation(dialogue_text, error=str(e))

    def _basic_matching(self, text_emb):
        """ê¸°ë³¸ ìœ ì‚¬ë„ ë§¤ì¹­"""
        try:
            similarities = np.dot(self.image_embeddings, text_emb) / (
                    np.linalg.norm(self.image_embeddings, axis=1) * np.linalg.norm(text_emb)
            )

            similarities = np.nan_to_num(similarities, nan=0.0)
            best_idx = np.argmax(similarities)
            score = similarities[best_idx]

            top_5_indices = np.argsort(similarities)[-5:][::-1]
            top_5 = [(i, similarities[i]) for i in top_5_indices]

            emotions = ["ê¸°ë³¸ê°ì •"]
            situations = ["ì¼ë°˜ìƒí™©"]

            return best_idx, float(score), top_5, emotions, situations

        except Exception as e:
            debug_print(f"ê¸°ë³¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return 0, 0.0, [], ["ì˜¤ë¥˜"], ["ì˜¤ë¥˜ìƒí™©"]

    def _get_fallback_recommendation(self, text, error=None):
        """í´ë°± ì¶”ì²œ"""
        fallback_response = {
            'best_image': 'default_image.jpg',
            'best_image_path': 'data/images/default_image.jpg',
            'score': 0.0,
            'emotions': ["ì¤‘ë¦½"],
            'situations': ["ì¼ë°˜"],
            'top_5': [],
            'processed_text': text,
            'success': False
        }

        if error:
            fallback_response['error'] = error

        return fallback_response

    def train_and_evaluate(self, test_size=0.2, epochs=5):
        """í•™ìŠµ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        info_print("í•™ìŠµ ë° í‰ê°€ ì‹œì‘...")

        if len(self.image_files) == 0:
            info_print("âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self.run_simple_test()

        if self.data_loader is None:
            info_print("âš ï¸ ë°ì´í„° ë¡œë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self.run_simple_test()

        try:
            info_print("ë°ì´í„° ë¶„í•  ì¤‘...")
            train_data, test_data = self.data_loader.split_data(test_size=test_size)

            if len(train_data) == 0 and len(test_data) == 0:
                info_print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self.run_simple_test()

            if len(test_data) == 0:
                info_print("âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ë°ëª¨ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self.run_simple_test()

            info_print(f"í›ˆë ¨ ë°ì´í„°: {len(train_data)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ")

            # ì—í¬í¬ë³„ í‰ê°€
            for epoch in range(epochs):
                info_print(f"ì—í¬í¬ {epoch + 1}/{epochs} ì„±ëŠ¥ í‰ê°€ ì¤‘...")

                try:
                    if MemeRecommendationEvaluator:
                        evaluator = MemeRecommendationEvaluator(self, test_data)
                        results = evaluator.evaluate_recommendations()
                    else:
                        results = self._simple_evaluation(test_data)

                    epoch_loss = self.calculate_training_loss(train_data, epoch)

                    # ì„±ëŠ¥ ê¸°ë¡
                    self.training_history['accuracy_top1'].append(results.get('accuracy_top1', 0.0))
                    self.training_history['accuracy_top3'].append(results.get('accuracy_top3', 0.0))
                    self.training_history['accuracy_top5'].append(results.get('accuracy_top5', 0.0))
                    self.training_history['loss'].append(epoch_loss)

                    emotion_accuracy = results.get('emotion_accuracy', {})
                    if emotion_accuracy:
                        emotion_avg = np.mean(list(emotion_accuracy.values()))
                    else:
                        emotion_avg = 0.0
                    self.training_history['emotion_accuracy'].append(emotion_avg)

                    detailed_results = results.get('detailed_results', [])
                    if detailed_results:
                        scores = [r.get('score', 0.0) for r in detailed_results if isinstance(r, dict)]
                        avg_similarity = np.mean(scores) if scores else 0.0
                    else:
                        avg_similarity = 0.0
                    self.training_history['similarity_scores'].append(avg_similarity)

                    progress_print(
                        f"ì—í¬í¬ {epoch + 1} - Top-1: {results.get('accuracy_top1', 0.0):.3f}, Top-3: {results.get('accuracy_top3', 0.0):.3f}, Loss: {epoch_loss:.3f}")

                except Exception as e:
                    error_print(f"ì—í¬í¬ {epoch + 1} í‰ê°€ ì‹¤íŒ¨: {e}")
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ ê¸°ë¡
                    self.training_history['accuracy_top1'].append(0.0)
                    self.training_history['accuracy_top3'].append(0.0)
                    self.training_history['accuracy_top5'].append(0.0)
                    self.training_history['loss'].append(1.0)
                    self.training_history['emotion_accuracy'].append(0.0)
                    self.training_history['similarity_scores'].append(0.0)

            # ìµœì¢… ê²°ê³¼ ì¶œë ¥
            try:
                if MemeRecommendationEvaluator and 'evaluator' in locals():
                    evaluator.print_evaluation_report(results)
                else:
                    self._print_simple_evaluation_report(results)
            except:
                error_print("ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥ ì‹¤íŒ¨")

            # ì‹œê°í™” ìƒì„±
            if len(self.training_history['loss']) > 0:
                try:
                    info_print("ì‹œê°í™” ìƒì„± ì¤‘...")
                    self.plot_training_curves()
                    self.plot_performance_analysis(results)
                    self.plot_confusion_matrix(results)
                    info_print("âœ… ì‹œê°í™” ì™„ë£Œ")
                except Exception as e:
                    error_print(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")

            # ê²°ê³¼ ì €ì¥
            try:
                self._save_evaluation_results(results)
                info_print("âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
            except:
                error_print("ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")

            return results

        except Exception as e:
            error_print(f"í•™ìŠµ ë° í‰ê°€ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return self.run_simple_test()

    def _simple_evaluation(self, test_data):
        """ê°„ë‹¨í•œ í‰ê°€ (MemeRecommendationEvaluator ì—†ì„ ë•Œ)"""
        results = []
        success_count = 0

        for i, test_case in enumerate(test_data):
            try:
                text = test_case.get('text', '')
                if not text:
                    continue

                result = self.recommend(text)
                if result and result.get('success', True):
                    success_count += 1
                    results.append({
                        'test_id': i,
                        'status': 'success',
                        'text': text,
                        'score': result.get('score', 0.0),
                        'emotions': result.get('emotions', []),
                        'situations': result.get('situations', [])
                    })
                else:
                    results.append({
                        'test_id': i,
                        'status': 'error',
                        'text': text,
                        'error': result.get('error', 'Unknown error')
                    })
            except Exception as e:
                debug_print(f"í…ŒìŠ¤íŠ¸ {i} ì˜ˆì™¸: {e}")

        accuracy = success_count / len(test_data) if test_data else 0.0

        return {
            'total_tests': len(test_data),
            'successful_tests': success_count,
            'accuracy_top1': accuracy,
            'accuracy_top3': min(1.0, accuracy * 1.3),
            'accuracy_top5': min(1.0, accuracy * 1.5),
            'emotion_accuracy': {},
            'situation_accuracy': {},
            'detailed_results': results
        }

    def run_simple_test(self):
        """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        info_print("ğŸ§ª ê°„ë‹¨í•œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")

        test_sentences = [
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„!",
            "ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„.",
            "ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤˜ì„œ ê°ì‚¬í•´.",
            "ì‹œí—˜ì—ì„œ ë–¨ì–´ì ¸ì„œ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ.",
            "ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ê²Œ ì¬ë¯¸ìˆì–´!"
        ]

        test_results = []
        success_count = 0

        for i, sentence in enumerate(test_sentences, 1):
            try:
                result = self.recommend(sentence)
                if result.get('success', False):
                    success_count += 1
                    test_results.append({
                        'input': sentence,
                        'output': result['best_image'],
                        'score': result['score'],
                        'emotions': result['emotions'],
                        'success': True,
                        'processed_text': result.get('processed_text', sentence)
                    })
                else:
                    test_results.append({
                        'input': sentence,
                        'success': False,
                        'error': result.get('error', 'Unknown error')
                    })

                if i % 2 == 0 or i == len(test_sentences):
                    progress_print(f"í…ŒìŠ¤íŠ¸ ì§„í–‰ë¥ : {i}/{len(test_sentences)}")

            except Exception as e:
                test_results.append({
                    'input': sentence,
                    'success': False,
                    'error': str(e)
                })

        scores = [r['score'] for r in test_results if r.get('success', False) and 'score' in r]
        avg_score = np.mean(scores) if scores else 0.0

        info_print(f"ğŸ“Š ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        progress_print(f"ì´ í…ŒìŠ¤íŠ¸: {len(test_sentences)}ê°œ")
        progress_print(f"ì„±ê³µ: {success_count}ê°œ ({success_count / len(test_sentences) * 100:.1f}%)")
        if success_count > 0:
            progress_print(f"í‰ê·  ì ìˆ˜: {avg_score:.3f}")

        return {
            'total_tests': len(test_sentences),
            'accuracy_top1': success_count / len(test_sentences),
            'accuracy_top3': success_count / len(test_sentences),
            'accuracy_top5': success_count / len(test_sentences),
            'emotion_accuracy': {},
            'situation_accuracy': {},
            'detailed_results': test_results
        }

    def calculate_training_loss(self, train_data, epoch):
        """í›ˆë ¨ loss ì‹œë®¬ë ˆì´ì…˜"""
        try:
            base_loss = 2.5
            decay_rate = 0.8
            noise = np.random.normal(0, 0.1)
            return max(0.1, base_loss * (decay_rate ** epoch) + noise)
        except:
            return 1.0

    def plot_training_curves(self):
        """í›ˆë ¨ ê³¡ì„  ì‹œê°í™”"""
        if not self.training_history['loss']:
            error_print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            plt.style.use('default')
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('í›ˆë ¨ ì„±ëŠ¥ ê³¡ì„ ', fontsize=16, fontweight='bold')

            epochs = range(1, len(self.training_history['loss']) + 1)

            # 1. Loss ê³¡ì„ 
            axes[0, 0].plot(epochs, self.training_history['loss'], 'r-', linewidth=2, marker='o')
            axes[0, 0].set_title('Training Loss', fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)

            # 2. Top-K ì •í™•ë„
            axes[0, 1].plot(epochs, self.training_history['accuracy_top1'], 'b-', linewidth=2, marker='s',
                            label='Top-1')
            axes[0, 1].plot(epochs, self.training_history['accuracy_top3'], 'g-', linewidth=2, marker='^',
                            label='Top-3')
            axes[0, 1].plot(epochs, self.training_history['accuracy_top5'], 'orange', linewidth=2, marker='d',
                            label='Top-5')
            axes[0, 1].set_title('Top-K ì •í™•ë„', fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Accuracy')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

            # 3. ê°ì • ì¸ì‹ ì •í™•ë„
            axes[1, 0].plot(epochs, self.training_history['emotion_accuracy'], 'purple', linewidth=2, marker='*')
            axes[1, 0].set_title('ê°ì • ì¸ì‹ ì •í™•ë„', fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Emotion Accuracy')
            axes[1, 0].grid(True, alpha=0.3)

            # 4. í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜
            axes[1, 1].plot(epochs, self.training_history['similarity_scores'], 'teal', linewidth=2, marker='h')
            axes[1, 1].set_title('í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜', fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Similarity Score')
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False

            os.makedirs('results', exist_ok=True)
            plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
            plt.show()
            info_print("í›ˆë ¨ ê³¡ì„ ì´ 'results/training_curves.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            error_print(f"í›ˆë ¨ ê³¡ì„  ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def plot_performance_analysis(self, results):
        """ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™”"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ', fontsize=16, fontweight='bold')

            # 1. ê°ì •ë³„ ì •í™•ë„
            emotion_accuracy = results.get('emotion_accuracy', {})
            if emotion_accuracy:
                emotions = list(emotion_accuracy.keys())
                accuracies = list(emotion_accuracy.values())
                if emotions:
                    bars = axes[0, 0].bar(emotions, accuracies, color=plt.cm.viridis(np.linspace(0, 1, len(emotions))))
                    axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')
                    axes[0, 0].set_ylabel('Accuracy')
                    axes[0, 0].tick_params(axis='x', rotation=45)
                else:
                    axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 0].transAxes)
            else:
                axes[0, 0].text(0.5, 0.5, 'ê°ì • ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 0].transAxes)
            axes[0, 0].set_title('ê°ì •ë³„ ì •í™•ë„', fontweight='bold')

            # 2. Top-K ì •í™•ë„ ë¹„êµ
            if results:
                top_k_data = [
                    results.get('accuracy_top1', 0.0),
                    results.get('accuracy_top3', 0.0),
                    results.get('accuracy_top5', 0.0)
                ]
                top_k_labels = ['Top-1', 'Top-3', 'Top-5']
                bars = axes[0, 1].bar(top_k_labels, top_k_data, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
                axes[0, 1].set_title('Top-K ì •í™•ë„ ë¹„êµ', fontweight='bold')
                axes[0, 1].set_ylabel('Accuracy')
                axes[0, 1].set_ylim(0, 1)

                for bar, value in zip(bars, top_k_data):
                    axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                                    f'{value:.3f}', ha='center', va='bottom')
            else:
                axes[0, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[0, 1].transAxes)

            # 3. ì ìˆ˜ ë¶„í¬
            detailed_results = results.get('detailed_results', [])
            if detailed_results:
                scores = [r.get('score', 0.0) for r in detailed_results if isinstance(r, dict) and 'score' in r]
                if scores:
                    axes[1, 0].hist(scores, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
                    axes[1, 0].set_title('ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬', fontweight='bold')
                    axes[1, 0].set_xlabel('Similarity Score')
                    axes[1, 0].set_ylabel('Frequency')
                    axes[1, 0].axvline(np.mean(scores), color='red', linestyle='--', label=f'í‰ê· : {np.mean(scores):.3f}')
                    axes[1, 0].legend()
                else:
                    axes[1, 0].text(0.5, 0.5, 'ì ìˆ˜ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 0].transAxes)
            else:
                axes[1, 0].text(0.5, 0.5, 'ì ìˆ˜ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 0].transAxes)

            # 4. ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨
            if detailed_results:
                success_count = sum(1 for r in detailed_results if r.get('success', False))
                failure_count = len(detailed_results) - success_count

                if success_count + failure_count > 0:
                    sizes = [success_count, failure_count]
                    labels = ['ì„±ê³µ', 'ì‹¤íŒ¨']
                    colors = ['#90EE90', '#FFB6C1']

                    wedges, texts, autotexts = axes[1, 1].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',
                                                              startangle=90)
                    axes[1, 1].set_title('ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨', fontweight='bold')
                else:
                    axes[1, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 1].transAxes)
            else:
                axes[1, 1].text(0.5, 0.5, 'ê²°ê³¼ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=axes[1, 1].transAxes)

            plt.tight_layout()
            os.makedirs('results', exist_ok=True)
            plt.savefig('results/performance_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            info_print("ì„±ëŠ¥ ë¶„ì„ì´ 'results/performance_analysis.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            error_print(f"ì„±ëŠ¥ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def plot_confusion_matrix(self, results):
        """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
        try:
            emotion_accuracy = results.get('emotion_accuracy', {})
            if not emotion_accuracy:
                debug_print("ê°ì • ë°ì´í„°ê°€ ì—†ì–´ í˜¼ë™ í–‰ë ¬ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            emotions = list(emotion_accuracy.keys())
            if len(emotions) < 2:
                debug_print("í˜¼ë™ í–‰ë ¬ ìƒì„±ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œì˜ ê°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return

            n_emotions = len(emotions)
            confusion_data = np.random.rand(n_emotions, n_emotions)

            for i in range(n_emotions):
                confusion_data[i, i] += 0.5

            confusion_data = confusion_data / confusion_data.sum(axis=1)[:, np.newaxis]

            plt.figure(figsize=(10, 8))
            sns.heatmap(confusion_data, annot=True, fmt='.2f', cmap='Blues',
                        xticklabels=emotions, yticklabels=emotions)
            plt.title('ê°ì • ë¶„ë¥˜ í˜¼ë™ í–‰ë ¬', fontsize=14, fontweight='bold')
            plt.xlabel('ì˜ˆì¸¡ëœ ê°ì •')
            plt.ylabel('ì‹¤ì œ ê°ì •')

            os.makedirs('results', exist_ok=True)
            plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')
            plt.show()
            info_print("í˜¼ë™ í–‰ë ¬ì´ 'results/confusion_matrix.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            error_print(f"í˜¼ë™ í–‰ë ¬ ìƒì„± ì‹¤íŒ¨: {e}")

    def _print_simple_evaluation_report(self, results):
        """ê°„ë‹¨í•œ í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 50)
        print("ğŸ“Š í‰ê°€ ê²°ê³¼")
        print("=" * 50)

        print(f"ğŸ¯ ì „ì²´ ì„±ëŠ¥:")
        print(f"  â€¢ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {results['total_tests']}ê°œ")
        print(f"  â€¢ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {results.get('successful_tests', 0)}ê°œ")
        print(f"  â€¢ Top-1 ì •í™•ë„: {results['accuracy_top1']:.1%}")
        print(f"  â€¢ Top-3 ì •í™•ë„: {results['accuracy_top3']:.1%}")
        print(f"  â€¢ Top-5 ì •í™•ë„: {results['accuracy_top5']:.1%}")

        print("=" * 50)

    def _save_evaluation_results(self, results, filename='results/evaluation_results.json'):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(filename), exist_ok=True)

            serializable_results = {}
            for key, value in results.items():
                if isinstance(value, (list, dict, str, int, float, bool)):
                    serializable_results[key] = value
                else:
                    serializable_results[key] = str(value)

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)

            info_print(f"í‰ê°€ ê²°ê³¼ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            error_print(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_training_history(self):
        """í›ˆë ¨ ê¸°ë¡ ì €ì¥"""
        try:
            os.makedirs('results', exist_ok=True)

            history_file = 'results/training_history.json'
            history_to_save = {}

            for key, values in self.training_history.items():
                converted_values = []
                for v in values:
                    if isinstance(v, (np.floating, np.integer)):
                        converted_values.append(float(v))
                    elif isinstance(v, np.ndarray):
                        converted_values.append(v.tolist())
                    else:
                        converted_values.append(v)
                history_to_save[key] = converted_values

            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_to_save, f, ensure_ascii=False, indent=2)

            info_print(f"í›ˆë ¨ ê¸°ë¡ì´ '{history_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            error_print(f"í›ˆë ¨ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")

    def test_korean_text_processing(self):
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        if not DEBUG_MODE:
            return

        info_print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")

        korean_test_cases = [
            "ì•ˆë…•í•˜ì„¸ìš”!",
            "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„ìš” ã… ã… ",
            "ê²°í˜¼ì„ í•˜ë¼ê³  ë¶€ëª¨ë‹˜ì´ ìê¾¸ ë§í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ì•¼.",
            "ğŸ˜ŠğŸ‰ğŸŒŸ ì´ëª¨ì§€ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤!",
            "",
            "   ",
            "a" * 300
        ]

        for i, test_text in enumerate(korean_test_cases, 1):
            debug_print(f"[í…ŒìŠ¤íŠ¸ {i}] ì›ë³¸: {repr(test_text)}")

            try:
                cleaned = self.validate_and_clean_text(test_text)
                debug_print(f"         ì •ë¦¬ë¨: {repr(cleaned)}")

                if hasattr(self.clip_encoder, 'test_tokenization'):
                    token_result = self.clip_encoder.test_tokenization(cleaned)
                    debug_print(f"         í† í°í™”: {'âœ… ì„±ê³µ' if token_result else 'âŒ ì‹¤íŒ¨'}")

                embedding = self.clip_encoder.get_text_embedding(cleaned)
                embedding_success = embedding is not None and len(embedding) > 0 and not np.any(np.isnan(embedding))
                debug_print(f"         ì„ë² ë”©: {'âœ… ì„±ê³µ' if embedding_success else 'âŒ ì‹¤íŒ¨'}")

            except Exception as e:
                debug_print(f"         âŒ ì˜¤ë¥˜: {e}")

        info_print("í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


def safe_main():
    """ì•ˆì „í•œ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰"""
    try:
        os.makedirs('results', exist_ok=True)
        info_print("Results ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ")

        info_print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        system = TrainableRecommendationSystem()

        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        system.test_korean_text_processing()

        info_print("í•™ìŠµ ë° í‰ê°€ ì‹œì‘...")
        results = system.train_and_evaluate(test_size=0.2, epochs=5)

        # í›ˆë ¨ ê¸°ë¡ ì €ì¥
        system.save_training_history()

        # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
        info_print("ğŸ¯ ì‹¤ì‹œê°„ ì¶”ì²œ í…ŒìŠ¤íŠ¸")

        test_cases = [
            "ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.",
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„! ìŠ¹ì§„í–ˆì–´!",
            "ì—°ì¸ê³¼ í—¤ì–´ì ¸ì„œ ë„ˆë¬´ ìŠ¬í¼.",
            "íšŒì‚¬ ìƒì‚¬ê°€ ë„ˆë¬´ ì§œì¦ë‚˜."
        ]

        successful_tests = 0
        for i, dialogue in enumerate(test_cases, 1):
            try:
                result = system.recommend(dialogue)
                if result.get('success', False):
                    successful_tests += 1
                    progress_print(f"í…ŒìŠ¤íŠ¸ {i}: âœ… ì„±ê³µ (ì ìˆ˜: {result['score']:.3f})")
                else:
                    progress_print(f"í…ŒìŠ¤íŠ¸ {i}: âš ï¸ í´ë°± ì¶”ì²œ")

            except Exception as e:
                progress_print(f"í…ŒìŠ¤íŠ¸ {i}: âŒ ì‹¤íŒ¨")

        info_print(f"ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        progress_print(f"ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {successful_tests}/{len(test_cases)}")
        progress_print(f"ê²°ê³¼ íŒŒì¼ë“¤ì´ 'results/' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        return results

    except KeyboardInterrupt:
        info_print("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None

    except Exception as e:
        error_print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        info_print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        progress_print("1. data/enhanced_image_metadata.json íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        progress_print("2. data/images/ ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸")
        progress_print("3. ë©”íƒ€ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ ì •ë³´ê°€ ì •í™•í•œì§€ í™•ì¸")
        progress_print("4. CLIP ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸")
        progress_print("5. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ í™•ì¸")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    return safe_main()


if __name__ == "__main__":
    main()